
@article{ratnapinda_learning_2015,
	series = {Special {JAL} {Issue} dedicated to {Uncertain} {Reasoning} at {FLAIRS}},
	title = {Learning discrete {Bayesian} network parameters from continuous data streams: {What} is the best strategy?},
	volume = {13},
	issn = {1570-8683},
	shorttitle = {Learning discrete {Bayesian} network parameters from continuous data streams},
	url = {http://www.sciencedirect.com/science/article/pii/S1570868315000464},
	doi = {10.1016/j.jal.2015.03.007},
	abstract = {We compare three approaches to learning numerical parameters of discrete Bayesian networks from continuous data streams: (1) the EM algorithm applied to all data, (2) the EM algorithm applied to data increments, and (3) the online EM algorithm. Our results show that learning from all data at each step, whenever feasible, leads to the highest parameter accuracy and model classification accuracy. When facing computational limitations, incremental learning approaches are a reasonable alternative. While the differences in speed between incremental algorithms are not large (online EM is slightly slower), for all but small data sets online EM tends to be more accurate than incremental EM.},
	number = {4, Part 2},
	urldate = {2016-11-23},
	journal = {Journal of Applied Logic},
	author = {Ratnapinda, Parot and Druzdzel, Marek J.},
	month = dec,
	year = {2015},
	keywords = {Bayesian networks, Parameter learning, EM algorithm},
	pages = {628--642},
	file = {ScienceDirect Full Text PDF:/afs/inf.ed.ac.uk/user/s09/s0929508/.zotero/zotero/zu1v7p1w.default/zotero/storage/B9UAV76K/Ratnapinda and Druzdzel - 2015 - Learning discrete Bayesian network parameters from.pdf:application/pdf;ScienceDirect Snapshot:/afs/inf.ed.ac.uk/user/s09/s0929508/.zotero/zotero/zu1v7p1w.default/zotero/storage/Q5XHMSXC/S1570868315000464.html:text/html}
}

@article{stone_interactively_2009,
	title = {Interactively {Shaping} {Agents} via {Human} {Reinforcement}: {The} {TAMER} {Framework}},
	shorttitle = {Interactively {Shaping} {Agents} via {Human} {Reinforcement}},
	url = {http://www.cs.utexas.edu/users/ai-lab/?KCAP09-knox},
	urldate = {2016-11-23},
	author = {Stone, W. Bradley Knox {and} Peter},
	year = {2009}
}

@inproceedings{shi_incremental_2010,
	title = {Incremental learning {Bayesian} network structures efficiently},
	doi = {10.1109/ICARCV.2010.5707313},
	abstract = {In this paper, a new hybrid incremental learning algorithm for Bayesian network structures is proposed. It develops a polynomial-time constraint-based technique to build up a candidate parents set for each domain variable, and a hill climbing search procedure is then employed to refine the current network structure under the guidance of those candidate parents sets. Our algorithm always offers considerable computational complexity savings while obtaining better model accuracy compared to existing incremental algorithms when dealing with complex real-world problems. The more complex the real-world problems are, the more significant the advantage our algorithm keeps is.},
	booktitle = {2010 11th {International} {Conference} on {Control} {Automation} {Robotics} {Vision}},
	author = {Shi, D. and Tan, S.},
	month = dec,
	year = {2010},
	keywords = {belief networks, computational complexity, learning (artificial intelligence), search problems, Bayesian network, hill climbing search procedure, hybrid incremental learning, polynomial time constraint based technique, Accuracy, Algorithm design and analysis, Approximation algorithms, Computational modeling, Insurance, incremental learning, structure learning},
	pages = {1719--1724}
}

@book{murphy_machine_2012,
	title = {Machine {Learning}: {A} {Probabilistic} {Perspective}},
	publisher = {MIT Press},
	author = {Murphy, K},
	year = {2012}
}

@inproceedings{fan_finding_2014,
	title = {Finding optimal {Bayesian} network structures with constraints learned from data},
	booktitle = {Proceedings of the 30th annual conference on uncertainty in artificial intelligence ({UAI}-14)},
	author = {Fan, Xiannian and Malone, Brandon and Yuan, Changhe},
	year = {2014},
	pages = {200--209}
}

@article{lake_building_2016,
	title = {Building {Machines} {That} {Learn} and {Think} {Like} {People}},
	journal = {arXiv preprint arXiv:1604.00289},
	author = {Lake, Brenden M and Ullman, Tomer D and Tenenbaum, Joshua B and Gershman, Samuel J},
	year = {2016}
}

@article{alcobe_incremental_2005,
	title = {Incremental methods for {Bayesian} network structure learning},
	volume = {18},
	number = {1},
	journal = {Artificial Intelligence Communications},
	author = {Alcobe, Josep Roure},
	year = {2005},
	pages = {61--62}
}

@inproceedings{roure_sequential_2006,
	title = {Sequential update of {ADtrees}},
	booktitle = {Proceedings of the 23rd international conference on machine learning},
	publisher = {ACM},
	author = {Roure, Josep and Moore, Andrew W},
	year = {2006},
	pages = {769--776}
}

@inproceedings{anderson_adtrees_1998,
	title = {{ADtrees} for {Fast} {Counting} and for {Fast} {Learning} of {Association} {Rules}.},
	booktitle = {{KDD}},
	author = {Anderson, Brigham S and Moore, Andrew W},
	year = {1998},
	pages = {134--138}
}

@article{tsamardinos_max-min_2006,
	title = {The max-min hill-climbing {Bayesian} network structure learning algorithm},
	volume = {65},
	number = {1},
	journal = {Machine learning},
	author = {Tsamardinos, Ioannis and Brown, Laura E and Aliferis, Constantin F},
	year = {2006},
	pages = {31--78}
}

@inproceedings{yasin_incremental_2013,
	title = {Incremental {Bayesian} network structure learning in high dimensional domains},
	booktitle = {Modeling, {Simulation} and {Applied} {Optimization} ({ICMSAO}), 2013 5th {International} {Conference} on},
	publisher = {IEEE},
	author = {Yasin, Ahmad and Leray, Philippe},
	year = {2013},
	pages = {1--6}
}

@inproceedings{osborne_ensemble-based_2004,
	title = {Ensemble-based {Active} {Learning} for {Parse} {Selection}.},
	booktitle = {{HLT}-{NAACL}},
	publisher = {Citeseer},
	author = {Osborne, Miles and Baldridge, Jason},
	year = {2004},
	pages = {89--96}
}

@article{harsanyi_games_2004,
	title = {Games with incomplete information played by “{Bayesian}” players, i–iii: part i. the basic model\&},
	volume = {50},
	number = {12\_supplement},
	journal = {Management science},
	author = {Harsanyi, John C},
	year = {2004},
	pages = {1804--1817}
}

@article{feinberg_games_2012,
	title = {Games with unawareness},
	author = {Feinberg, Yossi},
	year = {2012}
}

@inproceedings{albrecht_are_2015,
	address = {Amsterdam, Netherlands},
	title = {Are {You} {Doing} {What} {I} {Think} {You} {Are} {Doing}? {Criticising} {Uncertain} {Agent} {Models}},
	booktitle = {Proceedings of the 31st {Conference} on {Uncertainty} in {Artificial} {Intelligence} ({UAI}-15)},
	author = {Albrecht, S.V. and Ramamoorthy, S.},
	month = jul,
	year = {2015}
}

@book{sutton_reinforcement_1998,
	title = {Reinforcement {Learning}: {An} {Introduction}},
	publisher = {MIT Press},
	author = {Sutton, R. and Barto, A},
	year = {1998}
}

@article{grollman_donut_2011,
	title = {Donut as {I} do: {Learning} from failed demonstrations},
	journal = {Robotics and Automations (ICRA) 2011 IEEE International Conference},
	author = {Grollman, D. and Billard, A.},
	year = {2011}
}

@inproceedings{branavan_reading_2010,
	title = {Reading between the lines: {Learning} to map high-level instructions to commands},
	booktitle = {Proceedings of the 48th {Annual} {Meeting} of the {Association} for {Computational} {Linguistics}},
	publisher = {Association for Computational Linguistics},
	author = {Branavan, SRK and Zettlemoyer, Luke S and Barzilay, Regina},
	year = {2010},
	pages = {1268--1277}
}

@book{argall_tactile_2011,
	title = {Tactile guidance for policy adaptation},
	volume = {2},
	publisher = {Now Publishers Inc},
	author = {Argall, Brenna D and Sauser, Eric L and Billard, Aude G},
	year = {2011}
}

@article{chernova_interactive_2009,
	title = {Interactive policy learning through confidence-based autonomy},
	volume = {34},
	number = {1},
	journal = {Journal of Artificial Intelligence Research},
	author = {Chernova, Sonia and Veloso, Manuela},
	year = {2009},
	pages = {1}
}

@article{cakmak_designing_2012,
	title = {Designing robot learners that ask good questions},
	journal = {Proceedings of the 7th Annual ACM/IEEE International Conference on Human-Robot Interaction},
	author = {Cakmak, M.L. and Thomaz, A.},
	year = {2012}
}

@article{deng_deep_2014,
	title = {Deep {Learning}: {Methods} and {Applications}},
	journal = {Foundations and Trends in Signal Processing 7},
	author = {Deng, L. and Yu, D.},
	year = {2014}
}

@article{asher_commonsense_1991,
	title = {Commonsense {Entailment} : {A} modal theory of nonmonotonic reasoning},
	journal = {Proceedings of the 12th International Joint Conference on Artificial Intelligence},
	author = {Asher, N. and Morreau, M.},
	year = {1991}
}

@article{mnih_human-level_2015,
	title = {Human-level control through deep reinforcement learning},
	volume = {518},
	number = {7540},
	journal = {Nature},
	author = {Mnih, Volodymyr and Kavukcuoglu, Koray and Silver, David and Rusu, Andrei A and Veness, Joel and Bellemare, Marc G and Graves, Alex and Riedmiller, Martin and Fidjeland, Andreas K and Ostrovski, Georg and {others}},
	year = {2015},
	pages = {529--533}
}

@book{koller_probabilistic_2009,
	title = {Probabilistic {Graphical} {Models}: {Principles} and {Techniques}},
	publisher = {MIT Press},
	author = {Koller, D},
	year = {2009}
}

@article{bengio_representation_2013,
	title = {Representation {Learning}: {A} {Review} and {New} {Perspectives}},
	journal = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
	author = {Bengio, Y},
	year = {2013}
}

@article{buntine_theory_1991,
	title = {Theory {Refinement} on {Bayesian} {Networks}},
	volume = {abs/1303.5709},
	url = {http://arxiv.org/abs/1303.5709},
	journal = {CoRR},
	author = {Buntine, Wray L.},
	year = {1991}
}

@article{hansson_changes_1995,
	title = {Changes in {Preference}},
	journal = {Theory and Decision},
	author = {Hansson, S.},
	year = {1995}
}

@article{settles_active_2009,
	title = {Active learning literature survey},
	journal = {Computer Sciences Technical Report},
	author = {Settles, B},
	year = {2009}
}

@article{spohn_why_2009,
	title = {Why the {Received} {Models} of {Considering} {Preference} {Change} {Must} {Fail}},
	journal = {Preference Change: Approaches from Philosophy, Economics and Psychology},
	author = {Spohn, W.},
	year = {2009}
}

@inproceedings{boutilier_ucp-networks:_2001,
	title = {{UCP}-networks: {A} directed graphical representation of conditional utilities},
	booktitle = {Proceedings of the {Seventeenth} conference on {Uncertainty} in artificial intelligence},
	publisher = {Morgan Kaufmann Publishers Inc.},
	author = {Boutilier, Craig and Bacchus, Fahiem and Brafman, Ronen I},
	year = {2001},
	pages = {56--64}
}

@article{cadilhac_preference_2015,
	title = {Preference change},
	volume = {24},
	number = {3},
	journal = {Journal of Logic, Language and Information},
	author = {Cadilhac, Anaïs and Asher, Nicholas and Lascarides, Alex and Benamara, Farah},
	year = {2015},
	pages = {267--288}
}

@inproceedings{chen_empirical_1996,
	title = {An empirical study of smoothing techniques for language modeling},
	booktitle = {Proceedings of the 34th annual meeting on {Association} for {Computational} {Linguistics}},
	publisher = {Association for Computational Linguistics},
	author = {Chen, Stanley F and Goodman, Joshua},
	year = {1996},
	pages = {310--318}
}

@article{silander_simple_2012,
	title = {A simple approach for finding the globally optimal {Bayesian} network structure},
	journal = {arXiv preprint arXiv:1206.6875},
	author = {Silander, Tomi and Myllymaki, Petri},
	year = {2012}
}

@article{ellis_learning_2008,
	title = {Learning causal {Bayesian} network structures from experimental data},
	volume = {103},
	number = {482},
	journal = {Journal of the American Statistical Association},
	author = {Ellis, Byron and Wong, Wing Hung},
	year = {2008},
	pages = {778--789}
}

@inproceedings{yu_training_2016,
	title = {Training an adaptive dialogue policy for interactive learning of visually grounded word meanings},
	url = {https://www.aclweb.org/anthology/W/W16/W16-36.pdf#page=357},
	urldate = {2016-11-23},
	booktitle = {17th {Annual} {Meeting} of the {Special} {Interest} {Group} on {Discourse} and {Dialogue}},
	author = {Yu, Yanchao and Eshghi, Arash and Lemon, Oliver},
	year = {2016},
	pages = {339}
}

@article{larsson_formal_nodate,
	title = {Formal semantics for perceptual classification {PREPRINT} {VERSION}},
	url = {http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.434.340&rep=rep1&type=pdf},
	urldate = {2016-11-23},
	author = {Larsson, Staffan}
}

@inproceedings{forbes_robot_2015,
	title = {Robot {Programming} by {Demonstration} with situated spatial language understanding},
	doi = {10.1109/ICRA.2015.7139462},
	abstract = {Robot Programming by Demonstration (PbD) allows users to program a robot by demonstrating the desired behavior. Providing these demonstrations typically involves moving the robot through a sequence of states, often by physically manipulating it. This requires users to be co-located with the robot and have the physical ability to manipulate it. In this paper, we present a natural language based interface for PbD that removes these requirements and enables hands-free programming. We focus on programming object manipulation actions-our key insight is that such actions can be decomposed into known types of manipulator movements that are naturally described using spatial language; e.g., object reference expressions and prepositions. Our method takes a natural language command and the current world state to infer the intended movement command and its parametrization. We implement this method on a two-armed mobile manipulator and demonstrate the different types of manipulation actions that can be programmed with it. We compare it to a kinesthetic PbD interface and we demonstrate our method's ability to deal with incomplete language.},
	booktitle = {2015 {IEEE} {International} {Conference} on {Robotics} and {Automation} ({ICRA})},
	author = {Forbes, M. and Rao, R. P. N. and Zettlemoyer, L. and Cakmak, M.},
	month = may,
	year = {2015},
	keywords = {Computational modeling, inference mechanisms, manipulators, mobile robots, natural language processing, robot programming, PbD, hands-free programming, intended movement command inference, kinesthetic PbD interface, natural language based interface, natural language command, object manipulation action programming, object reference expressions, object reference prepositions, robot programming-by-demonstration, situated spatial language understanding, state sequence, two-armed mobile manipulator movements, Color, Context, Natural languages, Programming},
	pages = {2014--2020}
}

@article{lakkaraju_discovering_2016,
	title = {Discovering {Blind} {Spots} of {Predictive} {Models}: {Representations} and {Policies} for {Guided} {Exploration}},
	shorttitle = {Discovering {Blind} {Spots} of {Predictive} {Models}},
	url = {http://arxiv.org/abs/1610.09064},
	abstract = {Predictive models deployed in the world may assign incorrect labels to instances with high confidence. Such errors or unknown unknowns are rooted in model incompleteness, and typically arise because of the mismatch between training data and the cases seen in the open world. As the models are blind to such errors, input from an oracle is needed to identify these failures. In this paper, we formulate and address the problem of optimizing the discovery of unknown unknowns of any predictive model under a fixed budget, which limits the number of times an oracle can be queried for true labels. We propose a model-agnostic methodology which uses feedback from an oracle to both identify unknown unknowns and to intelligently guide the discovery. We employ a two-phase approach which first organizes the data into multiple partitions based on instance similarity, and then utilizes an explore-exploit strategy for discovering unknown unknowns across these partitions. We demonstrate the efficacy of our framework by varying the underlying causes of unknown unknowns across various applications. To the best of our knowledge, this paper presents the first algorithmic approach to the problem of discovering unknown unknowns of predictive models.},
	urldate = {2016-11-23},
	journal = {arXiv:1610.09064 [cs]},
	author = {Lakkaraju, Himabindu and Kamar, Ece and Caruana, Rich and Horvitz, Eric},
	month = oct,
	year = {2016},
	note = {arXiv: 1610.09064},
	keywords = {Computer Science - Artificial Intelligence}
}

@inproceedings{friedman_bayesian_1998,
	title = {The {Bayesian} structural {EM} algorithm},
	url = {http://dl.acm.org/citation.cfm?id=2074110},
	urldate = {2016-11-23},
	booktitle = {Proceedings of the {Fourteenth} conference on {Uncertainty} in artificial intelligence},
	publisher = {Morgan Kaufmann Publishers Inc.},
	author = {Friedman, Nir},
	year = {1998},
	pages = {129--138}
}

@book{cheeseman_bayesian_1996,
	title = {Bayesian {Classification}({AutoClass}):{Theory} and {Results}},
	shorttitle = {Bayesian {Classification}({AutoClass})},
	abstract = {We describe AutoClass, an approach to unsupervised classification based upon the classical mixture model, supplemented by a Bayesian method for determining the optimal classes. We include a moderately detailed exposition of the mathematics behind the AutoClass system. We emphasize that no current unsupervised classification system can produce maximally useful results when operated alone. It is the interaction between domain experts and the machine searching over the model space, that generates new knowledge. Both bring unique information and abilities to the database analysis task, and each enhances the others' effectiveness. We illustrate this point with several applications of AutoClass to complex real world databases, and describe the resulting successes and failures. 6.1 Introduction  This chapter is a summary of our experience in using an automatic classification program (AutoClass) to extract useful information from databases. It also gives an outline of the principles that under...},
	author = {Cheeseman, Peter and Stutz, John},
	year = {1996}
}

@inproceedings{elidan_discovering_2000,
	title = {Discovering hidden variables: {A} structure-based approach},
	volume = {13},
	shorttitle = {Discovering hidden variables},
	url = {http://ai.stanford.edu/~nir/Papers/ELFK1.pdf},
	urldate = {2016-11-23},
	booktitle = {{NIPS}},
	author = {Elidan, Gal and Lotner, Noam and Friedman, Nir and Koller, Daphne and {others}},
	year = {2000},
	pages = {479--485}
}

@article{elidan_learning_2005,
	title = {Learning hidden variable networks: {The} information bottleneck approach},
	volume = {6},
	shorttitle = {Learning hidden variable networks},
	url = {http://www.jmlr.org/papers/v6/elidan05a.html},
	number = {Jan},
	urldate = {2016-11-23},
	journal = {Journal of Machine Learning Research},
	author = {Elidan, Gal and Friedman, Nir},
	year = {2005},
	pages = {81--127}
}

@article{harmeling_greedy_2011,
	title = {Greedy learning of binary latent trees},
	volume = {33},
	url = {http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=5551151},
	number = {6},
	urldate = {2016-11-23},
	journal = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
	author = {Harmeling, Stefan and Williams, Christopher KI},
	year = {2011},
	pages = {1087--1097}
}

@article{zhou_empirical_2016,
	title = {An empirical study of {Bayesian} network parameter learning with monotonic influence constraints},
	volume = {87},
	issn = {0167-9236},
	url = {http://www.sciencedirect.com/science/article/pii/S0167923616300744},
	doi = {10.1016/j.dss.2016.05.001},
	abstract = {Learning the conditional probability table (CPT) parameters of Bayesian networks (BNs) is a key challenge in real-world decision support applications, especially when there are limited data available. A conventional way to address this challenge is to introduce domain knowledge/expert judgments that are encoded as qualitative parameter constraints. In this paper we focus on a class of constraints which is naturally encoded in the edges of BNs with monotonic influences. Experimental results indicate that such monotonic influence constraints are widespread in practical BNs (all BNs used in the study contain such monotonic influences). To exploit expert knowledge about such constraints we have developed an improved constrained optimization algorithm, which achieves good parameter learning performance using these constraints, especially when data are limited. Specifically, this algorithm outperforms the previous state-of-the-art and is also robust to errors in labelling the monotonic influences. The method is applied to a real world medical decision support BN where we had access to expert-provided constraints and real hospital data. The results suggest that incorporating expert judgments about monotonic influence constraints can lead to more accurate BNs for decision support and risk analysis.},
	urldate = {2016-11-23},
	journal = {Decision Support Systems},
	author = {Zhou, Yun and Fenton, Norman and Zhu, Cheng},
	month = jul,
	year = {2016},
	keywords = {BN parameter learning, Monotonic influences, Exterior constraints, Experiments on publicly available BNs, Real medical study},
	pages = {69--79}
}

@article{bramley_formalizing_2016,
	title = {Formalizing {Neurath}’s {Ship}: {Approximate} {Algorithms} for {Online} {Causal} {Learning}},
	shorttitle = {Formalizing {Neurath}’s {Ship}},
	url = {http://www.ucl.ac.uk/lagnado-lab/publications/neil/neuraths_ship_manuscript.pdf},
	urldate = {2016-11-23},
	author = {Bramley, Neil R. and Dayan, Peter and Griffiths, Thomas L. and Lagnado, David A.},
	year = {2016}
}

@article{hu_harnessing_2016,
	title = {Harnessing {Deep} {Neural} {Networks} with {Logic} {Rules}},
	url = {http://arxiv.org/abs/1603.06318},
	abstract = {Combining deep neural networks with structured logic rules is desirable to harness flexibility and reduce uninterpretability of the neural models. We propose a general framework capable of enhancing various types of neural networks (e.g., CNNs and RNNs) with declarative first-order logic rules. Specifically, we develop an iterative distillation method that transfers the structured information of logic rules into the weights of neural networks. We deploy the framework on a CNN for sentiment analysis, and an RNN for named entity recognition. With a few highly intuitive rules, we obtain substantial improvements and achieve state-of-the-art or comparable results to previous best-performing systems.},
	urldate = {2016-11-23},
	journal = {arXiv:1603.06318 [cs, stat]},
	author = {Hu, Zhiting and Ma, Xuezhe and Liu, Zhengzhong and Hovy, Eduard and Xing, Eric},
	month = mar,
	year = {2016},
	note = {arXiv: 1603.06318},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Learning, Computer Science - Computation and Language, Statistics - Machine Learning},
	annote = {Comment: Fix typos and experiment setting}
}

@inproceedings{tian_incremental_2001,
	title = {Incremental learning of {Bayesian} networks with hidden variables},
	url = {http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=989594},
	urldate = {2016-11-24},
	booktitle = {Data {Mining}, 2001. {ICDM} 2001, {Proceedings} {IEEE} {International} {Conference} on},
	publisher = {IEEE},
	author = {Tian, Fengzhan and Zhang, Hongwei and Lu, Yuchang and Shi, Chunyi},
	year = {2001},
	pages = {651--652}
}

@inproceedings{kim_evolutionary_2006,
	title = {Evolutionary aggregation and refinement of {Bayesian} networks},
	url = {http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=1688488},
	urldate = {2016-11-24},
	booktitle = {2006 {IEEE} {International} {Conference} on {Evolutionary} {Computation}},
	publisher = {IEEE},
	author = {Kim, Kyung-Joong and Cho, Sung-Bae},
	year = {2006},
	pages = {1513--1520}
}

@inproceedings{guo_novel_2006,
	title = {A novel hybrid evolutionary algorithm for learning {Bayesian} networks from incomplete data},
	url = {http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=1688409},
	urldate = {2016-11-24},
	booktitle = {2006 {IEEE} {International} {Conference} on {Evolutionary} {Computation}},
	publisher = {IEEE},
	author = {Guo, Yuan-Yuan and Wong, Man-Leung and Cai, Zhi-Hua},
	year = {2006},
	pages = {916--923}
}

@article{moore_cached_1998,
	title = {Cached {Sufficient} {Statistics} for {Efficient} {Machine} {Learning} with {Large} {Datasets}},
	volume = {8},
	url = {http://www.jair.org/media/453/live-453-1677-jair.ps.Z},
	number = {3},
	urldate = {2016-11-25},
	journal = {Journal of Artificial Intelligence Research},
	author = {Moore, A. W. and Lee, Mary Soon},
	year = {1998},
	pages = {67--91}
}

@inproceedings{kanagal_online_2008,
	title = {Online {Filtering}, {Smoothing} and {Probabilistic} {Modeling} of {Streaming} data},
	doi = {10.1109/ICDE.2008.4497525},
	abstract = {In this paper, we address the problem of extending a relational database system to facilitate efficient real-time application of dynamic probabilistic models to streaming data. We use the recently proposed abstraction of model-based views for this purpose, by allowing users to declaratively specify the model to be applied, and by presenting the output of the models to the user as a probabilistic database view. We support declarative querying over such views using an extended version of SQL that allows for querying probabilistic data. Underneath we use particle filters, a class of sequential Monte Carlo algorithms, to represent the present and historical states of the model as sets of weighted samples (particles) that are kept up-to-date as new data arrives. We develop novel techniques to convert the queries on the model-based view directly into queries over particle tables, enabling highly efficient query processing. Finally, we present experimental evaluation of our prototype implementation over several synthetic and real datasets, that demonstrates the feasibility of online modeling of streaming data using our system and establishes the advantages of tight integration between dynamic probabilistic models and databases.},
	booktitle = {2008 {IEEE} 24th {International} {Conference} on {Data} {Engineering}},
	author = {Kanagal, B. and Deshpande, A.},
	month = apr,
	year = {2008},
	keywords = {Monte Carlo methods, SQL, data analysis, particle filtering (numerical methods), probability, relational databases, data streaming, declarative query, dynamic probabilistic model, online filtering, particle filter, probabilistic database view, real-time application, relational database system, sequential Monte Carlo algorithm, Filtering, Global Positioning System, Hidden Markov models, Monitoring, Noise generators, Noise measurement, Real time systems, Smoothing methods},
	pages = {1160--1169}
}

@article{tzikas_variational_2008,
	title = {The variational approximation for {Bayesian} inference},
	volume = {25},
	url = {http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=4644060},
	number = {6},
	urldate = {2016-11-28},
	journal = {IEEE Signal Processing Magazine},
	author = {Tzikas, Dimitris G. and Likas, Aristidis C. and Galatsanos, Nikolaos P.},
	year = {2008},
	pages = {131--146}
}

@inproceedings{lam_using_1994,
	title = {Using new data to refine a {Bayesian} network},
	url = {http://dl.acm.org/citation.cfm?id=2074443},
	urldate = {2016-11-30},
	booktitle = {Proceedings of the {Tenth} international conference on {Uncertainty} in artificial intelligence},
	publisher = {Morgan Kaufmann Publishers Inc.},
	author = {Lam, Wai and Bacchus, Fahiem},
	year = {1994},
	pages = {383--390}
}

@inproceedings{dash_hybrid_1999,
	title = {A hybrid anytime algorithm for the construction of causal models from sparse data},
	url = {http://dl.acm.org/citation.cfm?id=2073813},
	urldate = {2016-11-30},
	booktitle = {Proceedings of the {Fifteenth} conference on {Uncertainty} in artificial intelligence},
	publisher = {Morgan Kaufmann Publishers Inc.},
	author = {Dash, Denver and Druzdzel, Marek J.},
	year = {1999},
	pages = {142--149}
}

@article{nielsen_adapting_2008,
	series = {Special {Section} on {Probabilistic} {Rough} {Sets} and {Special} {Section} on {PGM}’06},
	title = {Adapting {Bayes} network structures to non-stationary domains},
	volume = {49},
	issn = {0888-613X},
	url = {http://www.sciencedirect.com/science/article/pii/S0888613X08000224},
	doi = {10.1016/j.ijar.2008.02.007},
	abstract = {When an incremental structural learning method gradually modifies a Bayesian network (BN) structure to fit a sequential stream of observations, we call the process structural adaptation. Structural adaptation is useful when the learner is set to work in an unknown environment, where a BN is gradually being constructed as observations of the environment are made. Existing algorithms for incremental learning assume that the samples in the database have been drawn from a single underlying distribution. In this paper we relax this assumption, so that the underlying distribution can change during the sampling of the database. The proposed method can thus be used in unknown environments, where it is not even known whether the dynamics of the environment are stable. We state formal correctness results for our method, and demonstrate its feasibility experimentally.},
	number = {2},
	urldate = {2016-11-30},
	journal = {International Journal of Approximate Reasoning},
	author = {Nielsen, Søren Holbech and Nielsen, Thomas D.},
	month = oct,
	year = {2008},
	keywords = {Bayesian networks, Learning, Adaptation, Non-stationary domains},
	pages = {379--397}
}

@book{spirtes_causation_2000,
	title = {Causation, prediction, and search},
	url = {https://books.google.co.uk/books?hl=en&lr=&id=vV-U09kCdRwC&oi=fnd&pg=PR11&dq=Causation,+Prediction,+and+Search&ots=DW0PsqBNpb&sig=abY7SIXclU53sRsiHzmBkBUW1f0},
	urldate = {2016-11-30},
	publisher = {MIT press},
	author = {Spirtes, Peter and Glymour, Clark N. and Scheines, Richard},
	year = {2000}
}

@inproceedings{shahri_incremental_2006,
	address = {New York, NY, USA},
	series = {{PCAR} '06},
	title = {Incremental {Learning} of {Cognitive} {Concepts}: {A} {Hidden} {Variable} {Networks} {Approach}},
	isbn = {978-1-74052-130-7},
	shorttitle = {Incremental {Learning} of {Cognitive} {Concepts}},
	url = {http://doi.acm.org/10.1145/1232425.1232447},
	doi = {10.1145/1232425.1232447},
	abstract = {Representing and modeling knowledge in the face of uncertainty has always been a challenge in artificial intelligence. Graphical models are an apt way of representing uncertainty, and hidden variables in this framework are a way of abstraction of the knowledge. It seems that hidden variables can represent concepts, which reveal the relation among the observed phenomena and capture their cause and effect relationship through structure learning. Our concern is mostly on concept learning of situated agents, which learn while living, and adapt to their environment to maximize their expected reward. Therefore, we present an algorithm for sequential learning of Bayesian networks with hidden variables. The proposed algorithm employs the recent advancements in learning hidden variable networks for the batch case, and utilizes a mixture of approaches that allows for sequential learning of parameters and structure of the network. The incremental nature of this algorithm facilitates gradual learning of an agent, through its lifetime, as data is gathered progressively. Furthermore inference is made possible, when facing a large corpus of data that cannot be handled as a whole.},
	urldate = {2016-12-01},
	booktitle = {Proceedings of the 2006 {International} {Symposium} on {Practical} {Cognitive} {Agents} and {Robots}},
	publisher = {ACM},
	author = {Shahri, Saied Haidarian and Ahmadabady, Majid Nili},
	year = {2006},
	pages = {165--176}
}

@inproceedings{alcobe_incremental_2004,
	title = {Incremental hill-climbing search applied to {Bayesian} network structure learning},
	url = {https://www.researchgate.net/profile/Josep_Roure/publication/228570349_Incremental_Hill-Climbing_Search_Applied_to_Bayesian_Network_Structure_Learning/links/00b4952244e778a6f5000000.pdf},
	urldate = {2016-12-01},
	booktitle = {Proceedings of the 15th {European} {Conference} on {Machine} {Learning}, {Pisa}, {Italy}},
	author = {Alcobé, Josep Roure},
	year = {2004}
}

@inproceedings{friedman_sequential_1997,
	title = {Sequential update of {Bayesian} network structure},
	url = {http://dl.acm.org/citation.cfm?id=2074246},
	urldate = {2016-12-01},
	booktitle = {Proceedings of the {Thirteenth} conference on {Uncertainty} in artificial intelligence},
	publisher = {Morgan Kaufmann Publishers Inc.},
	author = {Friedman, Nir and Goldszmidt, Moises},
	year = {1997},
	pages = {165--174}
}

@incollection{neal_view_1998,
	title = {A view of the {EM} algorithm that justifies incremental, sparse, and other variants},
	url = {http://link.springer.com/chapter/10.1007/978-94-011-5014-9_12},
	urldate = {2016-12-01},
	booktitle = {Learning in graphical models},
	publisher = {Springer},
	author = {Neal, Radford M. and Hinton, Geoffrey E.},
	year = {1998},
	pages = {355--368}
}

@article{pena_dimensionality_2001,
	title = {Dimensionality reduction in unsupervised learning of conditional {Gaussian} networks},
	volume = {23},
	url = {http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=927460},
	number = {6},
	urldate = {2016-12-02},
	journal = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
	author = {Pena, Jose Manuel and Lozano, Jose Antonio and Larrañaga, Pedro and Inza, Iñaki},
	year = {2001},
	pages = {590--603}
}

@article{cappe_-line_2009,
	title = {On-line expectation–maximization algorithm for latent data models},
	volume = {71},
	url = {http://onlinelibrary.wiley.com/doi/10.1111/j.1467-9868.2009.00698.x/full},
	number = {3},
	urldate = {2016-12-05},
	journal = {Journal of the Royal Statistical Society: Series B (Statistical Methodology)},
	author = {Cappé, Olivier and Moulines, Eric},
	year = {2009},
	pages = {593--613}
}

@article{sato_-line_2000,
	title = {On-line {EM} algorithm for the normalized {Gaussian} network},
	volume = {12},
	url = {http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=6789693},
	number = {2},
	urldate = {2016-12-05},
	journal = {Neural computation},
	author = {Sato, Masa-Aki and Ishii, Shin},
	year = {2000},
	pages = {407--432}
}

@inproceedings{liang_online_2009,
	title = {Online {EM} for unsupervised models},
	url = {http://dl.acm.org/citation.cfm?id=1620843},
	urldate = {2016-12-05},
	booktitle = {Proceedings of human language technologies: {The} 2009 annual conference of the {North} {American} chapter of the association for computational linguistics},
	publisher = {Association for Computational Linguistics},
	author = {Liang, Percy and Klein, Dan},
	year = {2009},
	pages = {611--619}
}

@article{pena_improved_2000,
	title = {An improved {Bayesian} structural {EM} algorithm for learning {Bayesian} networks for clustering},
	volume = {21},
	issn = {0167-8655},
	url = {http://www.sciencedirect.com/science/article/pii/S0167865500000386},
	doi = {10.1016/S0167-8655(00)00038-6},
	abstract = {The application of the Bayesian Structural EM algorithm to learn Bayesian networks (BNs) for clustering implies a search over the space of BN structures alternating between two steps: an optimization of the BN parameters (usually by means of the EM algorithm) and a structural search for model selection. In this paper, we propose to perform the optimization of the BN parameters using an alternative approach to the EM algorithm: the BC+EM method. We provide experimental results to show that our proposal results in a more effective and efficient version of the Bayesian Structural EM algorithm for learning BNs for clustering.},
	number = {8},
	urldate = {2016-12-05},
	journal = {Pattern Recognition Letters},
	author = {Peña, J. M. and Lozano, J. A. and Larrañaga, P.},
	month = jul,
	year = {2000},
	keywords = {Bayesian networks, EM algorithm, Clustering, Bayesian Structural EM algorithm, Bound and collapse method},
	pages = {779--786}
}

@inproceedings{kulic_incremental_2010,
	title = {Incremental learning of human behaviors using hierarchical hidden {Markov} models},
	doi = {10.1109/IROS.2010.5650813},
	abstract = {This paper proposes a novel approach for extracting a model of movement primitives and their sequential relationships during online observation of human motion. In the proposed approach, movement primitives, modeled as hidden Markov models, are autonomously segmented and learned incrementally during observation. At the same time, a higher abstraction level hidden Markov model is also learned, encapsulating the relationship between the movement primitives. For the higher level model, each hidden state represents a motion primitive, and the observation function is based on the likelihood that the observed data is generated by the motion primitive model. An approach for incremental training of the higher order model during online observation is developed. The approach is validated on a dataset of continuous movement data.},
	booktitle = {2010 {IEEE}/{RSJ} {International} {Conference} on {Intelligent} {Robots} and {Systems}},
	author = {Kulić, D. and Nakamura, Y.},
	month = oct,
	year = {2010},
	keywords = {learning (artificial intelligence), incremental learning, mobile robots, Hidden Markov models, behavioural sciences, abstraction level, hierarchical hidden markov model, human behavior, human motion, observation function, online observation},
	pages = {4649--4655}
}

@article{ouivirach_incremental_2013,
	title = {Incremental {Behavior} {Modeling} and {Suspicious} {Activity} {Detection}},
	volume = {46},
	issn = {0031-3203},
	url = {http://dx.doi.org/10.1016/j.patcog.2012.10.008},
	doi = {10.1016/j.patcog.2012.10.008},
	abstract = {We propose and evaluate an efficient method for automatic identification of suspicious behavior in video surveillance data that incrementally learns scene-specific statistical models of human behavior without requiring storage of large databases of training data. The approach begins by building an initial set of models explaining the behaviors occurring in a small bootstrap dataset. The bootstrap procedure partitions the bootstrap set into clusters then assigns new observation sequences to clusters based on the statistical tests of HMM log likelihood scores. Cluster-specific likelihood thresholds are learned rather than set arbitrarily. After bootstrapping, each new sequence is used to incrementally update the sufficient statistics of the HMM it is assigned to. In an evaluation on a real-world testbed video surveillance dataset, we find that within 1week of observation, the incremental method's false alarm rate drops below that of a batch method on the same data. The incremental method obtains a false alarm rate of 2.2\% at a 91\% hit rate. The method is thus a practical and effective solution to the problem of inducing scene-specific statistical models useful for bringing suspicious behavior to the attention of human security personnel.},
	number = {3},
	urldate = {2016-12-07},
	journal = {Pattern Recogn.},
	author = {Ouivirach, Kan and Gharti, Shashi and Dailey, Matthew N.},
	month = mar,
	year = {2013},
	keywords = {incremental learning, Hidden Markov models, Anomaly detection, Behavior clustering, Bootstrapping, Sufficient statistics},
	pages = {671--680}
}

@article{wang_learning_2016,
	title = {Learning {Language} {Games} through {Interaction}},
	url = {http://arxiv.org/abs/1606.02447},
	urldate = {2016-12-20},
	journal = {arXiv preprint arXiv:1606.02447},
	author = {Wang, Sida I. and Liang, Percy and Manning, Christopher D.},
	year = {2016}
}

@article{cappe_online_2010,
	title = {Online {Expectation}-{Maximisation}},
	url = {http://arxiv.org/abs/1011.1745},
	abstract = {Tutorial chapter on the Online EM algorithm to appear in the volume 'Mixtures' edited by Kerrie Mengersen, Mike Titterington and Christian P. Robert.},
	urldate = {2017-01-30},
	journal = {arXiv:1011.1745 [stat]},
	author = {Cappé, Olivier},
	month = nov,
	year = {2010},
	note = {arXiv: 1011.1745},
	keywords = {Statistics - Computation}
}

@article{zhao_learning_nodate,
	title = {Learning {Bayesian} network structures under incremental construction curricula},
	issn = {0925-2312},
	url = {http://www.sciencedirect.com/science/article/pii/S0925231217304198},
	doi = {10.1016/j.neucom.2017.01.092},
	abstract = {Bayesian networks have been successfully applied to various tasks for probabilistic reasoning and causal modeling. One major challenge in the application of Bayesian networks is to learn the Bayesian network structures from data. In this paper, we take advantage of the idea of curriculum learning and learn Bayesian network structures by stages. At each stage a subnet is learned over a selected subset of the random variables. The selected subset grows with stages and eventually includes all the variables. We show that in our approach each target subnet is closer to the target Bayesian network than any of its predecessors. The experimental results show that our algorithm outperformed the state-of-the-art heuristic approach in learning Bayesian network structures under several different evaluation metrics.},
	urldate = {2017-03-14},
	journal = {Neurocomputing},
	author = {Zhao, Yanpeng and Chen, Yetian and Tu, Kewei and Tian, Jin},
	keywords = {Bayesian networks, structure learning, Curriculum learning}
}

@article{he_structural_2017,
	title = {Structural learning of causal networks},
	volume = {44},
	issn = {0385-7417, 1349-6964},
	url = {https://link.springer.com/article/10.1007/s41237-017-0018-8},
	doi = {10.1007/s41237-017-0018-8},
	abstract = {Causal network models are popular statistical tools to represent dependencies or causal relationships among variables in complex systems. Structural learning of causal networks is crucial to discover the causal knowledge and to infer casual effects. In this paper, we discuss structural learning of two types of graphical models, undirected graphs and directed acyclic graphs. We first introduce the methods for learning undirected graphical models. Then we discuss structural learning of directed acyclic graphs. We focus on the issues on model space of causal networks, decomposition learning of structures from observational data, local structural learning approaches and the active learning for optimal designs of intervention.},
	language = {en},
	number = {1},
	urldate = {2017-03-15},
	journal = {Behaviormetrika},
	author = {He, Yangbo and Jia, Jinzhu and Geng, Zhi},
	month = jan,
	year = {2017},
	pages = {287--305}
}

@article{murphy_active_2001,
	title = {Active learning of causal {Bayes} net structure},
	url = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.20.8206},
	urldate = {2017-03-16},
	author = {Murphy, Kevin P.},
	year = {2001}
}

@article{he_active_2008,
	title = {Active learning of causal networks with intervention experiments and optimal designs},
	volume = {9},
	url = {http://www.jmlr.org/papers/v9/he08a.html},
	number = {Nov},
	urldate = {2017-03-16},
	journal = {Journal of Machine Learning Research},
	author = {He, Yang-Bo and Geng, Zhi},
	year = {2008},
	pages = {2523--2547}
}

@article{tishby_information_2000,
	title = {The information bottleneck method},
	url = {https://arxiv.org/abs/physics/0004057},
	urldate = {2017-03-17},
	journal = {arXiv preprint physics/0004057},
	author = {Tishby, Naftali and Pereira, Fernando C. and Bialek, William},
	year = {2000}
}

@article{green_reversible_1995,
	title = {Reversible jump {Markov} chain {Monte} {Carlo} computation and {Bayesian} model determination},
	url = {http://www.jstor.org/stable/2337340},
	urldate = {2017-03-21},
	journal = {Biometrika},
	author = {Green, Peter J.},
	year = {1995},
	pages = {711--732}
}

@inproceedings{tian_testable_2002,
	title = {On the testable implications of causal models with hidden variables},
	url = {http://dl.acm.org/citation.cfm?id=2073938},
	urldate = {2017-03-22},
	booktitle = {Proceedings of the {Eighteenth} conference on {Uncertainty} in artificial intelligence},
	publisher = {Morgan Kaufmann Publishers Inc.},
	author = {Tian, Jin and Pearl, Judea},
	year = {2002},
	pages = {519--527}
}

@article{meila_learning_2000,
	title = {Learning with mixtures of trees},
	volume = {1},
	url = {http://www.jmlr.org/papers/v1/meila00a.html},
	number = {Oct},
	urldate = {2017-03-22},
	journal = {Journal of Machine Learning Research},
	author = {Meila, Marina and Jordan, Michael I.},
	year = {2000},
	pages = {1--48}
}

@article{choi_learning_2011,
	title = {Learning latent tree graphical models},
	volume = {12},
	url = {http://www.jmlr.org/papers/v12/choi11b.html},
	number = {May},
	urldate = {2017-03-22},
	journal = {Journal of Machine Learning Research},
	author = {Choi, Myung Jin and Tan, Vincent YF and Anandkumar, Animashree and Willsky, Alan S.},
	year = {2011},
	pages = {1771--1812}
}

@article{masegosa_new_2013,
	title = {New skeleton-based approaches for {Bayesian} structure learning of {Bayesian} networks},
	volume = {13},
	issn = {1568-4946},
	url = {http://www.sciencedirect.com/science/article/pii/S1568494612004541},
	doi = {10.1016/j.asoc.2012.09.029},
	abstract = {Automatically learning the graph structure of a single Bayesian network (BN) which accurately represents the underlying multivariate probability distribution of a collection of random variables is a challenging task. But obtaining a Bayesian solution to this problem based on computing the posterior probability of the presence of any edge or any directed path between two variables or any other structural feature is a much more involved problem, since it requires averaging over all the possible graph structures. For the former problem, recent advances have shown that search + score approaches find much more accurate structures if the search is constrained by a previously inferred skeleton (i.e. a relaxed structure with undirected edges which can be inferred using local search based methods). Based on similar ideas, we propose two novel skeleton-based approaches to approximate a Bayesian solution to the BN learning problem: a new stochastic search which tries to find directed acyclic graph (DAG) structures with a non-negligible score; and a new Markov chain Monte Carlo method over the DAG space. These two approaches are based on the same idea. In a first step, both employ a previously given skeleton and build a Bayesian solution constrained by this skeleton. In a second step, using the preliminary solution, they try to obtain a new Bayesian approximation but this time in an unconstrained graph space, which is the final outcome of the methods. As shown in the experimental evaluation, this new approach strongly boosts the performance of these two standard techniques proving that the idea of employing a skeleton to constrain the model space is also a successful strategy for performing Bayesian structure learning of BNs.},
	number = {2},
	urldate = {2017-04-03},
	journal = {Applied Soft Computing},
	author = {Masegosa, Andrés R. and Moral, Serafín},
	month = feb,
	year = {2013},
	keywords = {Bayesian networks, Probabilistic graphical models, Bayesian structure learning, Markov chain Monte Carlo, Stochastic search},
	pages = {1110--1120}
}

@article{jones_experiments_2005,
	title = {Experiments in {Stochastic} {Computation} for {High}-{Dimensional} {Graphical} {Models}},
	volume = {20},
	issn = {0883-4237},
	url = {http://www.jstor.org/stable/20061200},
	abstract = {We discuss the implementation, development and performance of methods of stochastic computation in Gaussian graphical models. We view these methods from the perspective of high-dimension model search, with a particular interest in the scalability with dimension of Markov chain Monte Carlo (MCMC) and other stochastic search methods. After reviewing the structure and context of undirected Gaussian graphical models and model uncertainty (covariance selection), we discuss prior specifications, including new priors over models, and then explore a number of examples using various methods of stochastic computation. Traditional MCMC methods are the point of departure for this experimentation; we then develop alternative stochastic search ideas and contrast this new approach with MCMC. Our examples range from low (12-20) to moderate (150) dimension, and combine simple synthetic examples with data analysis from gene expression studies. We conclude with comments about the need and potential for new computational methods in far higher dimensions, including constructive approaches to Gaussian graphical modeling and computation.},
	number = {4},
	urldate = {2017-04-03},
	journal = {Statistical Science},
	author = {Jones, Beatrix and Carvalho, Carlos and Dobra, Adrian and Hans, Chris and Carter, Chris and West, Mike},
	year = {2005},
	pages = {388--400}
}

@article{scott_feature-inclusion_2008,
	title = {Feature-{Inclusion} {Stochastic} {Search} for {Gaussian} {Graphical} {Models}},
	volume = {17},
	issn = {1061-8600},
	url = {http://amstat.tandfonline.com/doi/abs/10.1198/106186008X382683},
	doi = {10.1198/106186008X382683},
	abstract = {We describe a serial algorithm called feature-inclusion stochastic search, or FINCS, that uses online estimates of edge-inclusion probabilities to guide Bayesian model determination in Gaussian graphical models. FINCS is compared to MCMC, to Metropolis-based search methods, and to the popular lasso; it is found to be superior along a variety of dimensions, leading to better sets of discovered models, greater speed and stability, and reasonable estimates of edge-inclusion probabilities. We illustrate FINCS on an example involving mutual-fund data, where we compare the model-averaged predictive performance of models discovered with FINCS to those discovered by competing methods.},
	number = {4},
	urldate = {2017-04-03},
	journal = {Journal of Computational and Graphical Statistics},
	author = {Scott, James G and Carvalho, Carlos M},
	month = dec,
	year = {2008},
	pages = {790--808}
}

@article{masegosa_bayesian_2012,
	title = {A {Bayesian} stochastic search method for discovering {Markov} boundaries},
	volume = {35},
	issn = {0950-7051},
	url = {http://www.sciencedirect.com/science/article/pii/S0950705112001244},
	doi = {10.1016/j.knosys.2012.04.028},
	abstract = {The discovery of the Markov Boundary (MB) of a target variable using observational data plays a central role in feature selection and local causal structure inference. Most existing methods previously employed for this task rely on statistical independence tests and, in consequence, do not take into account the partial evidence that a finite data set gives about the existence of this kind of probabilistic relationships among random variables. In this work, we employ a novel stochastic search method which explicitly deals with this problem by eliciting multiple alternative Markov boundaries. This technique is based on a Bayesian approach for statistical tests and on a method to score the different alternative solutions. We have also evaluated an interactive procedure for integrating domain or expert knowledge a posteriori (after the learning process), in order to simplify and enrich the set of alternative inferred MBs. In an extensive experimental evaluation we show that this method is able to find a rich and accurate set of alternative MBs which, if properly combined, provide better inferences than other state-of-the-art approaches for this task. Moreover, we think that this new kind of methods, capable of capturing the inherent uncertainty of any real data set and which allows human interventions, can make practitioners feel more confident about the extracted knowledge than fully automatic approaches.},
	urldate = {2017-04-05},
	journal = {Knowledge-Based Systems},
	author = {Masegosa, Andrés R. and Moral, Serafín},
	month = nov,
	year = {2012},
	keywords = {Probabilistic graphical models, Stochastic search, Bayesian methods, Feature selection, Markov boundaries},
	pages = {211--223}
}

@inproceedings{zhu_statstream:_2002,
	title = {Statstream: {Statistical} monitoring of thousands of data streams in real time},
	shorttitle = {Statstream},
	url = {http://dl.acm.org/citation.cfm?id=1287401},
	urldate = {2017-05-15},
	booktitle = {Proceedings of the 28th international conference on {Very} {Large} {Data} {Bases}},
	publisher = {VLDB Endowment},
	author = {Zhu, Yunyue and Shasha, Dennis},
	year = {2002},
	pages = {358--369}
}

@article{bifet_adaptive_2009,
	title = {Adaptive learning and mining for data streams and frequent patterns},
	volume = {11},
	url = {http://dl.acm.org/citation.cfm?id=1656287},
	number = {1},
	urldate = {2017-05-16},
	journal = {ACM SIGKDD Explorations Newsletter},
	author = {Bifet, Albert},
	year = {2009},
	pages = {55--56}
}

@article{silva_survey_2011,
	title = {A survey on algorithmic debugging strategies},
	volume = {42},
	url = {http://www.sciencedirect.com/science/article/pii/S0965997811001311},
	number = {11},
	urldate = {2017-05-17},
	journal = {Advances in Engineering Software},
	author = {Silva, Josep},
	year = {2011},
	pages = {976--991}
}

@article{rosman_bayesian_2016,
	title = {Bayesian policy reuse},
	volume = {104},
	number = {1},
	journal = {Machine Learning},
	author = {Rosman, Benjamin and Hawasly, Majd and Ramamoorthy, Subramanian},
	year = {2016},
	pages = {99--127}
}

@inproceedings{zimmer_teacher-student_2014,
	title = {Teacher-student framework: a reinforcement learning approach},
	shorttitle = {Teacher-student framework},
	booktitle = {{AAMAS} {Workshop} {Autonomous} {Robots} and {Multirobot} {Systems}},
	author = {Zimmer, Matthieu and Viappiani, Paolo and Weng, Paul},
	year = {2014}
}

@inproceedings{torrey_teaching_2013,
	title = {Teaching on a budget: {Agents} advising agents in reinforcement learning},
	shorttitle = {Teaching on a budget},
	booktitle = {Proceedings of the 2013 international conference on {Autonomous} agents and multi-agent systems},
	publisher = {International Foundation for Autonomous Agents and Multiagent Systems},
	author = {Torrey, Lisa and Taylor, Matthew},
	year = {2013},
	pages = {1053--1060}
}

@phdthesis{rong_learning_2016,
	title = {Learning in the {Presence} of {Unawareness}},
	school = {Cornell University},
	author = {Rong, Nan},
	year = {2016}
}

@techreport{viero_intertemporal_2017,
	title = {An intertemporal model of growing awareness},
	author = {Vierø, Marie-Louise},
	year = {2017}
}

@article{halpern_mdps_2010,
	title = {{MDPs} with unawareness},
	journal = {arXiv preprint arXiv:1006.2204},
	author = {Halpern, Joseph Y. and Rong, Nan and Saxena, Ashutosh},
	year = {2010}
}

@article{vigorito_intrinsically_2010,
	title = {Intrinsically motivated hierarchical skill learning in structured environments},
	volume = {2},
	number = {2},
	journal = {IEEE Transactions on Autonomous Mental Development},
	author = {Vigorito, Christopher M. and Barto, Andrew G.},
	year = {2010},
	pages = {132--143}
}

@article{jonsson_causal_2006,
	title = {Causal graph based decomposition of factored mdps},
	volume = {7},
	number = {Nov},
	journal = {Journal of Machine Learning Research},
	author = {Jonsson, Anders and Barto, Andrew},
	year = {2006},
	pages = {2259--2301}
}

@article{jonsson_active_2007,
	title = {Active learning of dynamic bayesian networks in markov decision processes},
	journal = {Abstraction, Reformulation, and Approximation},
	author = {Jonsson, Anders and Barto, Andrew},
	year = {2007},
	pages = {273--284}
}

@article{vlassis_bayesian_2012,
	title = {Bayesian reinforcement learning},
	journal = {Reinforcement Learning},
	author = {Vlassis, Nikos and Ghavamzadeh, Mohammad and Mannor, Shie and Poupart, Pascal},
	year = {2012},
	pages = {359--386}
}

@inproceedings{ross_model-based_2008,
	title = {Model-based {Bayesian} reinforcement learning in large structured domains},
	volume = {2008},
	booktitle = {Uncertainty in artificial intelligence: proceedings of the... conference. {Conference} on {Uncertainty} in {Artificial} {Intelligence}},
	publisher = {NIH Public Access},
	author = {Ross, Stéphane and Pineau, Joelle},
	year = {2008},
	pages = {476}
}

@inproceedings{diuk_adaptive_2009,
	title = {The adaptive k-meteorologists problem and its application to structure learning and feature selection in reinforcement learning},
	booktitle = {Proceedings of the 26th {Annual} {International} {Conference} on {Machine} {Learning}},
	publisher = {ACM},
	author = {Diuk, Carlos and Li, Lihong and Leffler, Bethany R.},
	year = {2009},
	pages = {249--256}
}

@inproceedings{chakraborty_structure_2011,
	title = {Structure learning in ergodic factored {MDPs} without knowledge of the transition function's in-degree},
	booktitle = {Proceedings of the 28th {International} {Conference} on {Machine} {Learning} ({ICML}-11)},
	author = {Chakraborty, Doran and Stone, Peter},
	year = {2011},
	pages = {737--744}
}

@inproceedings{li_knows_2008,
	title = {Knows what it knows: a framework for self-aware learning},
	shorttitle = {Knows what it knows},
	booktitle = {Proceedings of the 25th international conference on {Machine} learning},
	publisher = {ACM},
	author = {Li, Lihong and Littman, Michael L. and Walsh, Thomas J.},
	year = {2008},
	pages = {568--575}
}

@article{brafman_r-max-general_2002,
	title = {R-max-a general polynomial time algorithm for near-optimal reinforcement learning},
	volume = {3},
	number = {Oct},
	journal = {Journal of Machine Learning Research},
	author = {Brafman, Ronen I. and Tennenholtz, Moshe},
	year = {2002},
	pages = {213--231}
}

@inproceedings{guestrin_algorithm-directed_2002,
	title = {Algorithm-directed exploration for model-based reinforcement learning in factored {MDPs}},
	booktitle = {{ICML}},
	author = {Guestrin, Carlos and Patrascu, Relu and Schuurmans, Dale},
	year = {2002},
	pages = {235--242}
}

@inproceedings{strehl_efficient_2007,
	title = {Efficient structure learning in factored-state {MDPs}},
	volume = {7},
	booktitle = {{AAAI}},
	author = {Strehl, Alexander L. and Diuk, Carlos and Littman, Michael L.},
	year = {2007},
	pages = {645--650}
}

@article{szita_factored_2008,
	title = {Factored value iteration converges},
	journal = {arXiv preprint arXiv:0801.2069},
	author = {Szita, István and Lorincz, Andras},
	year = {2008}
}

@inproceedings{koller_policy_2000,
	title = {Policy iteration for factored {MDPs}},
	booktitle = {Proceedings of the {Sixteenth} conference on {Uncertainty} in artificial intelligence},
	publisher = {Morgan Kaufmann Publishers Inc.},
	author = {Koller, Daphne and Parr, Ronald},
	year = {2000},
	pages = {326--334}
}

@article{guestrin_efficient_2003,
	title = {Efficient solution algorithms for factored {MDPs}},
	volume = {19},
	journal = {Journal of Artificial Intelligence Research},
	author = {Guestrin, Carlos and Koller, Daphne and Parr, Ronald and Venkataraman, Shobha},
	year = {2003},
	pages = {399--468}
}

@inproceedings{boutilier_exploiting_1995,
	title = {Exploiting structure in policy construction},
	volume = {14},
	booktitle = {{IJCAI}},
	author = {Boutilier, Craig and Dearden, Richard and Goldszmidt, Moises},
	year = {1995},
	pages = {1104--1113}
}

@article{richardson_markov_2006,
	title = {Markov logic networks},
	volume = {62},
	number = {1},
	journal = {Machine learning},
	author = {Richardson, Matthew and Domingos, Pedro},
	year = {2006},
	pages = {107--136}
}

@inproceedings{diuk_object-oriented_2008,
	title = {An object-oriented representation for efficient reinforcement learning},
	booktitle = {Proceedings of the 25th international conference on {Machine} learning},
	publisher = {ACM},
	author = {Diuk, Carlos and Cohen, Andre and Littman, Michael L.},
	year = {2008},
	pages = {240--247}
}

@book{sigaud_markov_2013,
	title = {Markov decision processes in artificial intelligence},
	publisher = {John Wiley \& Sons},
	author = {Sigaud, Olivier and Buffet, Olivier},
	year = {2013}
}

@inproceedings{friedman_learning_1998,
	title = {Learning the structure of dynamic probabilistic networks},
	booktitle = {Proceedings of the {Fourteenth} conference on {Uncertainty} in artificial intelligence},
	publisher = {Morgan Kaufmann Publishers Inc.},
	author = {Friedman, Nir and Murphy, Kevin and Russell, Stuart},
	year = {1998},
	pages = {139--147}
}

@article{boutilier_decision-theoretic_1999,
	title = {Decision-theoretic planning: {Structural} assumptions and computational leverage},
	volume = {11},
	shorttitle = {Decision-theoretic planning},
	number = {1},
	journal = {Journal of Artificial Intelligence Research},
	author = {Boutilier, Craig and Dean, Thomas and Hanks, Steve},
	year = {1999},
	pages = {94}
}

@article{van_otterlo_survey_2005,
	title = {A survey of reinforcement learning in relational domains},
	author = {Van Otterlo, Martijn},
	year = {2005}
}

@phdthesis{mccallum_reinforcement_1996,
	title = {Reinforcement learning with selective perception and hidden state},
	school = {University of Rochester. Dept. of Computer Science},
	author = {McCallum, Andrew Kachites and Ballard, Dana},
	year = {1996}
}

@article{kristensen_use_2002,
	title = {The use of a {Bayesian} network in the design of a decision support system for growing malting barley without use of pesticides},
	volume = {33},
	number = {3},
	journal = {Computers and Electronics in Agriculture},
	author = {Kristensen, Kristian and Rasmussen, Ilse A.},
	year = {2002},
	pages = {197--217}
}

@article{nielsen_learning_2004,
	title = {Learning a decision maker's utility function from (possibly) inconsistent behavior},
	volume = {160},
	number = {1-2},
	journal = {Artificial Intelligence},
	author = {Nielsen, Thomas D. and Jensen, Finn V.},
	year = {2004},
	pages = {53--78}
}

@incollection{suryadi_learning_1999,
	title = {Learning models of other agents using influence diagrams},
	booktitle = {{UM}99 {User} {Modeling}},
	publisher = {Springer},
	author = {Suryadi, Dicky and Gmytrasiewicz, Piotr J.},
	year = {1999},
	pages = {223--232}
}

@inproceedings{torrey_relational_2006,
	title = {Relational skill transfer via advice taking},
	booktitle = {{ICML} {Workshop} on {Structural} {Knowledge} {Transfer} for {Machine} {Learning}},
	author = {Torrey, Lisa and Shavlik, Jude and Walker, Trevor and Maclin, Richard},
	year = {2006}
}

@article{friedman_being_2003,
	title = {Being {Bayesian} about network structure. {A} {Bayesian} approach to structure discovery in {Bayesian} networks},
	volume = {50},
	number = {1-2},
	journal = {Machine learning},
	author = {Friedman, Nir and Koller, Daphne},
	year = {2003},
	pages = {95--125}
}

@inproceedings{lakkaraju_identifying_2017,
	title = {Identifying {Unknown} {Unknowns} in the {Open} {World}: {Representations} and {Policies} for {Guided} {Exploration}.},
	shorttitle = {Identifying {Unknown} {Unknowns} in the {Open} {World}},
	booktitle = {{AAAI}},
	author = {Lakkaraju, Himabindu and Kamar, Ece and Caruana, Rich and Horvitz, Eric},
	year = {2017},
	pages = {2124--2132}
}

@inproceedings{ide_generating_2004,
	title = {Generating random {Bayesian} networks with constraints on induced width},
	booktitle = {Proceedings of the 16th european conference on artificial intelligence},
	publisher = {IOS Press},
	author = {Ide, Jaime S. and Cozman, Fabio G. and Ramos, Fabio T.},
	year = {2004},
	pages = {353--357}
}

@inproceedings{degris_learning_2006,
	title = {Learning the structure of factored markov decision processes in reinforcement learning problems},
	booktitle = {Proceedings of the 23rd international conference on {Machine} learning},
	publisher = {ACM},
	author = {Degris, Thomas and Sigaud, Olivier and Wuillemin, Pierre-Henri},
	year = {2006},
	pages = {257--264}
}

@article{howard_influence_2005,
	title = {Influence diagrams},
	volume = {2},
	number = {3},
	journal = {Decision Analysis},
	author = {Howard, Ronald A. and Matheson, James E.},
	year = {2005},
	pages = {127--143}
}

@inproceedings{braziunas_preference_2006,
	title = {Preference elicitation and generalized additive utility},
	volume = {21},
	booktitle = {Proceedings of the national conference on artificial intelligence},
	publisher = {Menlo Park, CA; Cambridge, MA; London; AAAI Press; MIT Press; 1999},
	author = {Braziunas, Darius and Boutilier, Craig},
	year = {2006},
	pages = {1573}
}

@inproceedings{boutilier_ucp-networks:_2001-1,
	title = {{UCP}-networks: {A} directed graphical representation of conditional utilities},
	shorttitle = {{UCP}-networks},
	booktitle = {Proceedings of the {Seventeenth} conference on {Uncertainty} in artificial intelligence},
	publisher = {Morgan Kaufmann Publishers Inc.},
	author = {Boutilier, Craig and Bacchus, Fahiem and Brafman, Ronen I.},
	year = {2001},
	pages = {56--64}
}

@article{ross_model-based_2008-1,
	title = {Model-{Based} {Bayesian} {Reinforcement} {Learning} in {Large} {Structured} {Domains}},
	volume = {2008},
	issn = {1525-3384},
	url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4629999/},
	abstract = {Model-based Bayesian reinforcement learning has generated significant interest in the AI community as it provides an elegant solution to the optimal exploration-exploitation tradeoff in classical reinforcement learning. Unfortunately, the applicability of this type of approach has been limited to small domains due to the high complexity of reasoning about the joint posterior over model parameters. In this paper, we consider the use of factored representations combined with online planning techniques, to improve scalability of these methods. The main contribution of this paper is a Bayesian framework for learning the structure and parameters of a dynamical system, while also simultaneously planning a (near-)optimal sequence of actions.},
	urldate = {2017-12-14},
	journal = {Uncertainty in artificial intelligence : proceedings of the ... conference. Conference on Uncertainty in Artificial Intelligence},
	author = {Ross, Stéphane and Pineau, Joelle},
	month = jul,
	year = {2008},
	pmid = {26539065},
	pmcid = {PMC4629999},
	pages = {476--483}
}

@inproceedings{jonsson_automated_2001,
	title = {Automated state abstraction for options using the {U}-tree algorithm},
	author = {Jonsson, Anders and Barto, Andrew G.},
	year = {2001},
	pages = {1054--1060}
}

@article{brafman_r-max-general_2002-1,
	title = {R-max-a general polynomial time algorithm for near-optimal reinforcement learning},
	volume = {3},
	number = {Oct},
	journal = {Journal of Machine Learning Research},
	author = {Brafman, Ronen I. and Tennenholtz, Moshe},
	year = {2002},
	pages = {213--231},
	file = {Fulltext:/afs/inf.ed.ac.uk/user/s09/s0929508/.zotero/zotero/zu1v7p1w.default/zotero/storage/UF8JUIPI/Brafman and Tennenholtz - 2002 - R-max-a general polynomial time algorithm for near.pdf:application/pdf;Snapshot:/afs/inf.ed.ac.uk/user/s09/s0929508/.zotero/zotero/zu1v7p1w.default/zotero/storage/B373W3S4/Brafman and Tennenholtz - 2002 - R-max-a general polynomial time algorithm for near.html:text/html}
}

@article{fachantidis_learning_2017,
	title = {Learning to {Teach} {Reinforcement} {Learning} {Agents}},
	volume = {1},
	copyright = {http://creativecommons.org/licenses/by/3.0/},
	url = {http://www.mdpi.com/2504-4990/1/1/2},
	doi = {10.3390/make1010002},
	abstract = {In this article, we study the transfer learning model of action advice under a budget. We focus on reinforcement learning teachers providing action advice to heterogeneous students playing the game of Pac-Man under a limited advice budget. First, we examine several critical factors affecting advice quality in this setting, such as the average performance of the teacher, its variance and the importance of reward discounting in advising. The experiments show that the best performers are not always the best teachers and reveal the non-trivial importance of the coefficient of variation (CV) as a statistic for choosing policies that generate advice. The CV statistic relates variance to the corresponding mean. Second, the article studies policy learning for distributing advice under a budget. Whereas most methods in the relevant literature rely on heuristics for advice distribution, we formulate the problem as a learning one and propose a novel reinforcement learning algorithm capable of learning when to advise or not. The proposed algorithm is able to advise even when it does not have knowledge of the student’s intended action and needs significantly less training time compared to previous learning approaches. Finally, in this article, we argue that learning to advise under a budget is an instance of a more generic learning problem: Constrained Exploitation Reinforcement Learning.},
	language = {en},
	number = {1},
	urldate = {2018-01-11},
	journal = {Machine Learning and Knowledge Extraction},
	author = {Fachantidis, Anestis and Taylor, Matthew E. and Vlahavas, Ioannis},
	month = dec,
	year = {2017},
	keywords = {action advice, machine learning, machine teaching, reinforcement learning, transfer learning},
	pages = {2}
}

@article{taylor_transfer_2009,
	title = {Transfer learning for reinforcement learning domains: {A} survey},
	volume = {10},
	shorttitle = {Transfer learning for reinforcement learning domains},
	number = {Jul},
	journal = {Journal of Machine Learning Research},
	author = {Taylor, Matthew E. and Stone, Peter},
	year = {2009},
	pages = {1633--1685}
}

@article{karni_reverse_2013,
	title = {"{Reverse} {Bayesianism}": {A} choice-based theory of growing awareness},
	volume = {103},
	shorttitle = {" {Reverse} {Bayesianism}"},
	number = {7},
	journal = {American Economic Review},
	author = {Karni, Edi and Viero, Marie-Louise},
	year = {2013},
	pages = {2790--2810}
}

@article{pearl_theoretical_2018,
	title = {Theoretical {Impediments} to {Machine} {Learning} {With} {Seven} {Sparks} from the {Causal} {Revolution}},
	journal = {arXiv preprint arXiv:1801.04016},
	author = {Pearl, Judea},
	year = {2018}
}

@inproceedings{chen_deepdriving:_2015,
	title = {Deepdriving: {Learning} affordance for direct perception in autonomous driving},
	shorttitle = {Deepdriving},
	booktitle = {Computer {Vision} ({ICCV}), 2015 {IEEE} {International} {Conference} on},
	publisher = {IEEE},
	author = {Chen, Chenyi and Seff, Ari and Kornhauser, Alain and Xiao, Jianxiong},
	year = {2015},
	pages = {2722--2730}
}

@misc{darpa-baa-16-53_broad_2016,
	title = {Broad agency announcement on explainable artificial intelligence (xai)},
	author = {DARPA-BAA-16-53},
	year = {2016}
}

@inproceedings{zettlemoyer_online_2007,
	title = {Online learning of relaxed {CCG} grammars for parsing to logical form},
	booktitle = {Proceedings of the 2007 {Joint} {Conference} on {Empirical} {Methods} in {Natural} {Language} {Processing} and {Computational} {Natural} {Language} {Learning} ({EMNLP}-{CoNLL})},
	author = {Zettlemoyer, Luke and Collins, Michael},
	year = {2007}
}

@article{albrecht_exploiting_2016,
	title = {Exploiting causality for selective belief filtering in dynamic {Bayesian} networks},
	volume = {55},
	journal = {Journal of Artificial Intelligence Research},
	author = {Albrecht, Stefano V. and Ramamoorthy, Subramanian},
	year = {2016},
	pages = {1135--1178}
}

@article{alchourron_logic_1985,
	title = {On the logic of theory change: {Partial} meet contraction and revision functions},
	volume = {50},
	shorttitle = {On the logic of theory change},
	number = {2},
	journal = {The journal of symbolic logic},
	author = {Alchourrón, Carlos E. and Gärdenfors, Peter and Makinson, David},
	year = {1985},
	pages = {510--530}
}

@article{alchourron_logic_1985-1,
	title = {On the logic of theory change: {Partial} meet contraction and revision functions},
	volume = {50},
	shorttitle = {On the logic of theory change},
	number = {2},
	journal = {The journal of symbolic logic},
	author = {Alchourrón, Carlos E. and Gärdenfors, Peter and Makinson, David},
	year = {1985},
	pages = {510--530}
}

@article{artzi_weakly_2013,
	title = {Weakly supervised learning of semantic parsers for mapping instructions to actions},
	volume = {1},
	journal = {Transactions of the Association of Computational Linguistics},
	author = {Artzi, Yoav and Zettlemoyer, Luke},
	year = {2013},
	pages = {49--62}
}

@book{asher_logics_2003,
	title = {Logics of conversation},
	publisher = {Cambridge University Press},
	author = {Asher, Nicholas and Lascarides, Alex},
	year = {2003}
}

@article{bengio_representation_2013-1,
	title = {Representation learning: {A} review and new perspectives},
	volume = {35},
	shorttitle = {Representation learning},
	number = {8},
	journal = {IEEE transactions on pattern analysis and machine intelligence},
	author = {Bengio, Yoshua and Courville, Aaron and Vincent, Pascal},
	year = {2013},
	pages = {1798--1828}
}

@inproceedings{besbes_stochastic_2014,
	title = {Stochastic multi-armed-bandit problem with non-stationary rewards},
	booktitle = {Advances in neural information processing systems},
	author = {Besbes, Omar and Gur, Yonatan and Zeevi, Assaf},
	year = {2014},
	pages = {199--207}
}

@article{bielza_modeling_2010,
	title = {Modeling challenges with influence diagrams: {Constructing} probability and utility models},
	volume = {49},
	shorttitle = {Modeling challenges with influence diagrams},
	number = {4},
	journal = {Decision Support Systems},
	author = {Bielza, Concha and Gomez, Manuel and Shenoy, Prakash P.},
	year = {2010},
	pages = {354--364}
}

@article{board_two_2011,
	title = {Two models of unawareness: {Comparing} the object-based and the subjective-state-space approaches},
	volume = {179},
	shorttitle = {Two models of unawareness},
	number = {1},
	journal = {Synthese},
	author = {Board, Oliver J. and Chung, Kim-Sau and Schipper, Burkhard C.},
	year = {2011},
	pages = {13--34}
}

@inproceedings{bos_wide-coverage_2004,
	title = {Wide-coverage semantic representations from a {CCG} parser},
	booktitle = {Proceedings of the 20th international conference on {Computational} {Linguistics}},
	publisher = {Association for Computational Linguistics},
	author = {Bos, Johan and Clark, Stephen and Steedman, Mark and Curran, James R. and Hockenmaier, Julia},
	year = {2004},
	pages = {1240}
}

@article{chouard_go_2016,
	title = {The {Go} {Files}: {AI} computer wraps up 4-1 victory against human champion},
	shorttitle = {The {Go} {Files}},
	journal = {Nature News},
	author = {Chouard, Tanguy},
	year = {2016}
}

@inproceedings{da_silva_dealing_2006,
	title = {Dealing with non-stationary environments using context detection},
	booktitle = {Proceedings of the 23rd international conference on {Machine} learning},
	publisher = {ACM},
	author = {Da Silva, Bruno C. and Basso, Eduardo W. and Bazzan, Ana LC and Engel, Paulo M.},
	year = {2006},
	pages = {217--224}
}

@inproceedings{dobnik_modelling_2012,
	title = {Modelling language, action, and perception in type theory with records},
	booktitle = {International {Workshop} on {Constraint} {Solving} and {Language} {Processing}},
	publisher = {Springer},
	author = {Dobnik, Simon and Cooper, Robin and Larsson, Staffan},
	year = {2012},
	pages = {70--91}
}

@article{feinberg_subjective_2004,
	title = {Subjective reasoning-games with unawareness},
	author = {Feinberg, Yossi},
	year = {2004}
}

@inproceedings{forbes_robot_2015-1,
	title = {Robot programming by demonstration with situated spatial language understanding},
	booktitle = {Robotics and {Automation} ({ICRA}), 2015 {IEEE} {International} {Conference} on},
	publisher = {IEEE},
	author = {Forbes, Maxwell and Rao, Rajesh PN and Zettlemoyer, Luke and Cakmak, Maya},
	year = {2015},
	pages = {2014--2020}
}

@inproceedings{friedman_bayesian_1998-1,
	title = {The {Bayesian} structural {EM} algorithm},
	booktitle = {Proceedings of the {Fourteenth} conference on {Uncertainty} in artificial intelligence},
	publisher = {Morgan Kaufmann Publishers Inc.},
	author = {Friedman, Nir},
	year = {1998},
	pages = {129--138}
}

@article{grice_logic_1975,
	title = {Logic and conversation},
	journal = {1975},
	author = {Grice, H. Paul},
	year = {1975},
	pages = {41--58}
}

@article{groenendijk_semantic_1982,
	title = {Semantic analysis of wh-complements},
	volume = {5},
	number = {2},
	journal = {Linguistics and Philosophy},
	author = {Groenendijk, Joroen and Stokhof, Martin},
	year = {1982},
	pages = {175--233}
}

@article{halpern_reasoning_2013,
	title = {Reasoning about knowledge of unawareness revisited},
	volume = {65},
	number = {2},
	journal = {Mathematical Social Sciences},
	author = {Halpern, Joseph Y. and Rego, Leandro C.},
	year = {2013},
	pages = {73--84}
}

@article{hansson_changes_1995-1,
	title = {Changes in preference},
	volume = {38},
	number = {1},
	journal = {Theory and Decision},
	author = {Hansson, Sven Ove},
	year = {1995},
	pages = {1--28}
}

@article{heifetz_dynamic_2013,
	title = {Dynamic unawareness and rationalizable behavior},
	volume = {81},
	journal = {Games and Economic Behavior},
	author = {Heifetz, Aviad and Meier, Martin and Schipper, Burkhard C.},
	year = {2013},
	pages = {50--68}
}

@article{hinton_fast_2006,
	title = {A fast learning algorithm for deep belief nets},
	volume = {18},
	number = {7},
	journal = {Neural computation},
	author = {Hinton, Geoffrey E. and Osindero, Simon and Teh, Yee-Whye},
	year = {2006},
	pages = {1527--1554}
}

@article{hobbs_interpretation_1993,
	title = {Interpretation as abduction},
	volume = {63},
	number = {1-2},
	journal = {Artificial intelligence},
	author = {Hobbs, Jerry R. and Stickel, Mark E. and Appelt, Douglas E. and Martin, Paul},
	year = {1993},
	pages = {69--142}
}

@article{howard_influence_2005-1,
	title = {Influence diagrams},
	volume = {2},
	number = {3},
	journal = {Decision Analysis},
	author = {Howard, Ronald A. and Matheson, James E.},
	year = {2005},
	pages = {127--143}
}

@article{hristov_grounding_2017,
	title = {Grounding {Symbols} in {Multi}-{Modal} {Instructions}},
	journal = {arXiv preprint arXiv:1706.00355},
	author = {Hristov, Yordan and Penkov, Svetlin and Lascarides, Alex and Ramamoorthy, Subramanian},
	year = {2017}
}

@inproceedings{ide_generating_2004-1,
	title = {Generating random {Bayesian} networks with constraints on induced width},
	volume = {16},
	booktitle = {{ECAI}},
	author = {Ide, Jaime Shinsuke and Cozman, Fabio Gagliardi and Ramos, Fabio Tozeto},
	year = {2004},
	pages = {323}
}

@inproceedings{knox_interactively_2009,
	title = {Interactively shaping agents via human reinforcement: {The} {TAMER} framework},
	shorttitle = {Interactively shaping agents via human reinforcement},
	booktitle = {Proceedings of the fifth international conference on {Knowledge} capture},
	publisher = {ACM},
	author = {Knox, W. Bradley and Stone, Peter},
	year = {2009},
	pages = {9--16}
}

@inproceedings{lakkaraju_identifying_2017-1,
	title = {Identifying {Unknown} {Unknowns} in the {Open} {World}: {Representations} and {Policies} for {Guided} {Exploration}.},
	volume = {1},
	shorttitle = {Identifying {Unknown} {Unknowns} in the {Open} {World}},
	booktitle = {{AAAI}},
	author = {Lakkaraju, Himabindu and Kamar, Ece and Caruana, Rich and Horvitz, Eric},
	year = {2017},
	pages = {2}
}

@article{larsson_formal_2013,
	title = {Formal semantics for perceptual classification},
	volume = {25},
	number = {2},
	journal = {Journal of logic and computation},
	author = {Larsson, Staffan},
	year = {2013},
	pages = {335--369}
}

@inproceedings{leonetti_reinforcement_2011,
	title = {Reinforcement learning through global stochastic search in {N}-{MDPs}},
	booktitle = {Joint {European} {Conference} on {Machine} {Learning} and {Knowledge} {Discovery} in {Databases}},
	publisher = {Springer},
	author = {Leonetti, Matteo and Iocchi, Luca and Ramamoorthy, Subramanian},
	year = {2011},
	pages = {326--340}
}

@techreport{jing_modeling_2008,
	title = {Modeling {Unawareness} in {Arbitrary} {State} {Spaces}},
	institution = {Penn Institute for Economic Research, Department of Economics, University of Pennsylvania},
	author = {Jing, Li},
	year = {2008}
}

@phdthesis{liang_semi-supervised_2005,
	type = {{PhD} {Thesis}},
	title = {Semi-supervised learning for natural language},
	school = {Massachusetts Institute of Technology},
	author = {Liang, Percy},
	year = {2005}
}

@inproceedings{liebman_autonomous_2017,
	title = {Autonomous {Model} {Management} via {Reinforcement} {Learning}},
	booktitle = {Proceedings of the 16th {Conference} on {Autonomous} {Agents} and {MultiAgent} {Systems}},
	publisher = {International Foundation for Autonomous Agents and Multiagent Systems},
	author = {Liebman, Elad and Zavesky, Eric and Stone, Peter},
	year = {2017},
	pages = {1601--1603}
}

@phdthesis{mccallum_reinforcement_1996-1,
	type = {{PhD} {Thesis}},
	title = {Reinforcement learning with selective perception and hidden state},
	school = {University of Rochester. Dept. of Computer Science},
	author = {McCallum, Andrew Kachites and Ballard, Dana},
	year = {1996}
}

@article{nielsen_learning_2004-1,
	title = {Learning a decision maker's utility function from (possibly) inconsistent behavior},
	volume = {160},
	number = {1-2},
	journal = {Artificial Intelligence},
	author = {Nielsen, Thomas D. and Jensen, Finn V.},
	year = {2004},
	pages = {53--78}
}

@article{poole_probabilistic_1993,
	title = {Probabilistic {Horn} abduction and {Bayesian} networks},
	volume = {64},
	number = {1},
	journal = {Artificial intelligence},
	author = {Poole, David},
	year = {1993},
	pages = {81--129}
}

@article{reddy_transforming_2016,
	title = {Transforming dependency structures to logical forms for semantic parsing},
	volume = {4},
	journal = {Transactions of the Association for Computational Linguistics},
	author = {Reddy, Siva and Täckström, Oscar and Collins, Michael and Kwiatkowski, Tom and Das, Dipanjan and Steedman, Mark and Lapata, Mirella},
	year = {2016},
	pages = {127--140}
}

@phdthesis{rong_learning_2016-1,
	type = {{PhD} {Thesis}},
	title = {Learning in the {Presence} of {Unawareness}},
	school = {Cornell University},
	author = {Rong, Nan},
	year = {2016}
}

@inproceedings{silver_machine_2011,
	title = {Machine lifelong learning: challenges and benefits for artificial general intelligence},
	shorttitle = {Machine lifelong learning},
	booktitle = {International {Conference} on {Artificial} {General} {Intelligence}},
	publisher = {Springer},
	author = {Silver, Daniel L.},
	year = {2011},
	pages = {370--375}
}

@article{siskind_computational_1996,
	title = {A computational study of cross-situational techniques for learning word-to-meaning mappings},
	volume = {61},
	number = {1-2},
	journal = {Cognition},
	author = {Siskind, Jeffrey Mark},
	year = {1996},
	pages = {39--91}
}

@incollection{suryadi_learning_1999-1,
	title = {Learning models of other agents using influence diagrams},
	booktitle = {{UM}99 {User} {Modeling}},
	publisher = {Springer},
	author = {Suryadi, Dicky and Gmytrasiewicz, Piotr J.},
	year = {1999},
	pages = {223--232}
}

@book{thrun_learning_2012,
	title = {Learning to learn},
	publisher = {Springer Science \& Business Media},
	author = {Thrun, Sebastian and Pratt, Lorien},
	year = {2012}
}

@article{karni_awareness_2017,
	title = {Awareness of unawareness: {A} theory of decision making in the face of ignorance},
	volume = {168},
	shorttitle = {Awareness of unawareness},
	url = {https://ideas.repec.org/a/eee/jetheo/v168y2017icp301-328.html},
	abstract = {In the wake of growing awareness, decision makers anticipate that they might acquire knowledge that, in their current state of ignorance, is unimaginable. Supposedly, this anticipation manifests itself in the decision makers' choice behavior. In this paper we model the anticipation of growing awareness, lay choice-based axiomatic foundations to a subjective expected utility representation of beliefs about the likelihood of discovering unknown consequences, and assign utility to consequences that are not only unimaginable but may also be nonexistent. In so doing, we maintain the flavor of reverse Bayesianism of Karni and Vierø (2013, 2015).},
	language = {en},
	number = {C},
	urldate = {2018-06-20},
	journal = {Journal of Economic Theory},
	author = {Karni, Edi and Viero, Marie-Louise},
	year = {2017},
	keywords = {Awareness, Ignorance, Reverse Bayesianism, Unawareness, Utility of indescribable consequences},
	pages = {301--328}
}

@book{savage_foundations_1972,
	title = {The {Foundations} of {Statistics}},
	isbn = {978-0-486-62349-8},
	abstract = {Classic analysis of the foundations of statistics and development of personal probability, one of the greatest controversies in modern statistical thought. Revised edition. Calculus, probability, statistics, and Boolean algebra are recommended.},
	language = {en},
	publisher = {Courier Corporation},
	author = {Savage, Leonard J.},
	month = jun,
	year = {1972},
	note = {Google-Books-ID: zSv6dBWneMEC},
	keywords = {Mathematics / General, Mathematics / Probability \& Statistics / General, Social Science / Statistics}
}

@article{fagin_belief_1987,
	title = {Belief, awareness, and limited reasoning},
	volume = {34},
	issn = {0004-3702},
	url = {http://www.sciencedirect.com/science/article/pii/0004370287900038},
	doi = {10.1016/0004-3702(87)90003-8},
	abstract = {Several new logics for belief and knowledge are introduced and studied, all of which have the property that agents are not logically omniscient. In particular, in these logics, the set of beliefs of an agent does not necessarily contain all valid formulas. Thus, these logics are more suitable than traditional logics for modelling beliefs of humans (or machines) with limited reasoning capabilities. Our first logic is essentially an extension of Levesque's logic of implicit and explicit belief, where we extend to allow multiple agents and higher-level belief (i.e., beliefs about beliefs). Our second logic deals explicitly with “awareness,” where, roughly speaking, it is necessary to be aware of a concept before one can have beliefs about it. Our third logic gives a model of “local reasoning,” where an agent is viewed as a “society of minds,” each with its own cluster of beliefs, which may contradict each other.},
	number = {1},
	urldate = {2018-06-20},
	journal = {Artificial Intelligence},
	author = {Fagin, Ronald and Halpern, Joseph Y.},
	month = dec,
	year = {1987},
	pages = {39--76}
}

@techreport{li_modelilng_2008,
	address = {Rochester, NY},
	type = {{SSRN} {Scholarly} {Paper}},
	title = {Modelilng {Unawareness} in {Arbitrary} {State} {Spaces}},
	url = {https://papers.ssrn.com/abstract=1151335},
	abstract = {I develop a set-theoretic model of unawareness without making any structural assumptions on the underlying state space. Unawareness is characterized as a measurability constraint that results in players' reasoning about a "coarse" subjective algebra of events. The model is shown to be essentially equivalent to the product model in Li (2007), indicating that such a measurability constraint can be captured by restrictions on the dimensions of the state space without loss of generality. I use a variant of the partition model to examine the case of partial unawareness, where the player is aware of a question but unaware of some possible answers to that question, and characterize the player's knowledge hierarchies from his subjective perspective.},
	language = {en},
	number = {ID 1151335},
	urldate = {2018-06-20},
	institution = {Social Science Research Network},
	author = {Li, Jing},
	month = jan,
	year = {2008},
	keywords = {information, information partition, partial unawareness, the state space, unawareness}
}

@article{boutilier_stochastic_2000,
	title = {Stochastic dynamic programming with factored representations},
	volume = {121},
	issn = {0004-3702},
	url = {http://www.sciencedirect.com/science/article/pii/S0004370200000333},
	doi = {10.1016/S0004-3702(00)00033-3},
	abstract = {Markov decision processes (MDPs) have proven to be popular models for decision-theoretic planning, but standard dynamic programming algorithms for solving MDPs rely on explicit, state-based specifications and computations. To alleviate the combinatorial problems associated with such methods, we propose new representational and computational techniques for MDPs that exploit certain types of problem structure. We use dynamic Bayesian networks (with decision trees representing the local families of conditional probability distributions) to represent stochastic actions in an MDP, together with a decision-tree representation of rewards. Based on this representation, we develop versions of standard dynamic programming algorithms that directly manipulate decision-tree representations of policies and value functions. This generally obviates the need for state-by-state computation, aggregating states at the leaves of these trees and requiring computations only for each aggregate state. The key to these algorithms is a decision-theoretic generalization of classic regression analysis, in which we determine the features relevant to predicting expected value. We demonstrate the method empirically on several planning problems, showing significant savings for certain types of domains. We also identify certain classes of problems for which this technique fails to perform well and suggest extensions and related ideas that may prove useful in such circumstances. We also briefly describe an approximation scheme based on this approach.},
	number = {1},
	urldate = {2018-06-20},
	journal = {Artificial Intelligence},
	author = {Boutilier, Craig and Dearden, Richard and Goldszmidt, Moisés},
	month = aug,
	year = {2000},
	keywords = {Bayesian networks, Abstraction, Decision trees, Decision-theoretic planning, Markov decision processes, Regression},
	pages = {49--107}
}

@article{boutilier_decision-theoretic_1999-1,
	title = {Decision-{Theoretic} {Planning}: {Structural} {Assumptions} and {Computational} {Leverage}},
	volume = {11},
	issn = {1076-9757},
	shorttitle = {Decision-{Theoretic} {Planning}},
	url = {https://www.jair.org/index.php/jair/article/view/10237},
	doi = {10.1613/jair.575},
	language = {en-US},
	urldate = {2018-06-20},
	journal = {Journal of Artificial Intelligence Research},
	author = {Boutilier, C. and Dean, T. and Hanks, S.},
	month = jul,
	year = {1999},
	pages = {1--94}
}

@inproceedings{hoey_spudd:_1999,
	address = {San Francisco, CA, USA},
	series = {{UAI}'99},
	title = {{SPUDD}: {Stochastic} {Planning} {Using} {Decision} {Diagrams}},
	isbn = {978-1-55860-614-2},
	shorttitle = {{SPUDD}},
	url = {http://dl.acm.org/citation.cfm?id=2073796.2073828},
	abstract = {Recently, structured methods for solving factored Markov decisions processes (MDPs) with large state spaces have been proposed recently to allow dynamic programming to be applied without the need for complete state enumeration. We propose and examine a new value iteration algorithm for MDPs that uses algebraic decision diagrams (ADDs) to represent value functions and policies, assuming an ADD input representation of the MDP. Dynamic programming is implemented via ADD manipulation. We demonstrate our method on a class of large MDPs (up to 63 million states) and show that significant gains can be had when compared to tree-structured representations (with up to a thirty-fold reduction in the number of nodes required to represent optimal value functions).},
	urldate = {2018-06-20},
	booktitle = {Proceedings of the {Fifteenth} {Conference} on {Uncertainty} in {Artificial} {Intelligence}},
	publisher = {Morgan Kaufmann Publishers Inc.},
	author = {Hoey, Jesse and St-Aubin, Robert and Hu, Alan and Boutilier, Craig},
	year = {1999},
	pages = {279--288}
}

@article{van_otterlo_intensional_2009,
	series = {Special {Issue}: {Reinforcement} {Learning}},
	title = {Intensional dynamic programming. {A} {Rosetta} stone for structured dynamic programming},
	volume = {64},
	issn = {0196-6774},
	url = {http://www.sciencedirect.com/science/article/pii/S0196677409000376},
	doi = {10.1016/j.jalgor.2009.04.004},
	abstract = {We present intensional dynamic programming (IDP), a generic framework for structured dynamic programming over atomic, propositional and relational representations of states and actions. We first develop set-based dynamic programming and show its equivalence with classical dynamic programming. We then show how to describe state sets intensionally using any form of structured knowledge representation and obtain a generic algorithm that can optimally solve large, even infinite, MDPs without explicit state space enumeration. We derive two new Bellman backup operators and algorithms. In order to support the view of IDP as a Rosetta stone for structured dynamic programming, we review many existing techniques that employ either propositional or relational knowledge representation frameworks.},
	number = {4},
	urldate = {2018-06-20},
	journal = {Journal of Algorithms},
	author = {van Otterlo, Martijn},
	month = oct,
	year = {2009},
	keywords = {Dynamic programming, Knowledge representation, Markov decision process},
	pages = {169--191}
}

@misc{noauthor_interactive_nodate,
	title = {An interactive approach for {Bayesian} network learning using domain/expert knowledge - {Semantic} {Scholar}},
	url = {/paper/An-interactive-approach-for-Bayesian-network-using-Masegosa-Moral/6f8459739bcbf047c9319f8063184bc5af88734c},
	abstract = {Using domain/expert knowledge when learning Bayesian networks from data has been considered a promising idea since the very beginning of the field. However, in most of the previously proposed approaches, human experts do not play an active role in the learning process. Once their knowledge is elicited, they do not participate any more. The interactive approach for integrating domain/expert knowledge we propose in this work aims to be more efficient and effective. In contrast to previous approaches, our method performs an active interaction with the expert in order to guide the search based learning process. This method relies on identifying the edges of the graph structure which are more unreliable considering the information present in the learning data. Another contribution of our approach is the integration of domain/expert knowledge at different stages of the learning process of a Bayesian network: while learning the skeleton and when directing the edges of the directed acyclic graph structure.},
	urldate = {2018-06-20}
}

@article{masegosa_interactive_2013,
	title = {An interactive approach for {Bayesian} network learning using domain/expert knowledge},
	volume = {54},
	issn = {0888-613X},
	url = {http://www.sciencedirect.com/science/article/pii/S0888613X13000698},
	doi = {10.1016/j.ijar.2013.03.009},
	abstract = {Using domain/expert knowledge when learning Bayesian networks from data has been considered a promising idea since the very beginning of the field. However, in most of the previously proposed approaches, human experts do not play an active role in the learning process. Once their knowledge is elicited, they do not participate any more. The interactive approach for integrating domain/expert knowledge we propose in this work aims to be more efficient and effective. In contrast to previous approaches, our method performs an active interaction with the expert in order to guide the search based learning process. This method relies on identifying the edges of the graph structure which are more unreliable considering the information present in the learning data. Another contribution of our approach is the integration of domain/expert knowledge at different stages of the learning process of a Bayesian network: while learning the skeleton and when directing the edges of the directed acyclic graph structure.},
	number = {8},
	urldate = {2018-06-20},
	journal = {International Journal of Approximate Reasoning},
	author = {Masegosa, Andrés R. and Moral, Serafín},
	month = oct,
	year = {2013},
	keywords = {Bayesian networks, Probabilistic graphical models, Stochastic search, Domain expert knowledge, Interactive structure learning},
	pages = {1168--1181}
}

@book{pearl_probabilistic_1988,
	title = {Probabilistic {Reasoning} in {Intelligent} {Systems}},
	publisher = {Morgan Kaufmann},
	author = {Pearl, Judea},
	year = {1988}
}

@article{tsamardinos_max-min_2006-1,
	title = {The max-min hill-climbing {Bayesian} network structure learning algorithm},
	volume = {65},
	issn = {0885-6125, 1573-0565},
	url = {https://link.springer.com/article/10.1007/s10994-006-6889-7},
	doi = {10.1007/s10994-006-6889-7},
	abstract = {We present a new algorithm for Bayesian network structure learning, called Max-Min Hill-Climbing (MMHC). The algorithm combines ideas from local learning, constraint-based, and search-and-score techniques in a principled and effective way. It first reconstructs the skeleton of a Bayesian network and then performs a Bayesian-scoring greedy hill-climbing search to orient the edges. In our extensive empirical evaluation MMHC outperforms on average and in terms of various metrics several prototypical and state-of-the-art algorithms, namely the PC, Sparse Candidate, Three Phase Dependency Analysis, Optimal Reinsertion, Greedy Equivalence Search, and Greedy Search. These are the first empirical results simultaneously comparing most of the major Bayesian network algorithms against each other. MMHC offers certain theoretical advantages, specifically over the Sparse Candidate algorithm, corroborated by our experiments. MMHC and detailed results of our study are publicly available at http://www.dsl-lab.org/supplements/mmhc\_paper/mmhc\_index.html.},
	language = {en},
	number = {1},
	urldate = {2018-06-20},
	journal = {Machine Learning},
	author = {Tsamardinos, Ioannis and Brown, Laura E. and Aliferis, Constantin F.},
	month = oct,
	year = {2006},
	pages = {31--78}
}

@article{bartlett_integer_2017,
	series = {Combining {Constraint} {Solving} with {Mining} and {Learning}},
	title = {Integer {Linear} {Programming} for the {Bayesian} network structure learning problem},
	volume = {244},
	issn = {0004-3702},
	url = {http://www.sciencedirect.com/science/article/pii/S0004370215000417},
	doi = {10.1016/j.artint.2015.03.003},
	abstract = {Bayesian networks are a commonly used method of representing conditional probability relationships between a set of variables in the form of a directed acyclic graph (DAG). Determination of the DAG which best explains observed data is an NP-hard problem [1]. This problem can be stated as a constrained optimisation problem using Integer Linear Programming (ILP). This paper explores how the performance of ILP-based Bayesian network learning can be improved through ILP techniques and in particular through the addition of non-essential, implied constraints. There are exponentially many such constraints that can be added to the problem. This paper explores how these constraints may best be generated and added as needed. The results show that using these constraints in the best discovered configuration can lead to a significant improvement in performance and show significant improvement in speed using a state-of-the-art Bayesian network structure learner.},
	urldate = {2018-06-20},
	journal = {Artificial Intelligence},
	author = {Bartlett, Mark and Cussens, James},
	month = mar,
	year = {2017},
	keywords = {Bayesian networks, Constrained optimisation, Cutting planes, Integer Linear Programming, Separation},
	pages = {258--271}
}

@misc{noauthor_notitle_nodate,
	url = {https://scholar.googleusercontent.com/scholar.bib?q=info:YmCtHFLzhWgJ:scholar.google.com/&output=citation&scisig=AAGBfm0AAAAAWyqHDOICdqZd_R86Un3e3bSw9S14E7ru&scisf=4&ct=citation&cd=-1&hl=en},
	urldate = {2018-06-20}
}

@article{eaton_bayesian_2012,
	title = {Bayesian structure learning using dynamic programming and {MCMC}},
	url = {http://arxiv.org/abs/1206.5247},
	abstract = {MCMC methods for sampling from the space of DAGs can mix poorly due to the local nature of the proposals that are commonly used. It has been shown that sampling from the space of node orders yields better results [FK03, EW06]. Recently, Koivisto and Sood showed how one can analytically marginalize over orders using dynamic programming (DP) [KS04, Koi06]. Their method computes the exact marginal posterior edge probabilities, thus avoiding the need for MCMC. Unfortunately, there are four drawbacks to the DP technique: it can only use modular priors, it can only compute posteriors over modular features, it is difficult to compute a predictive density, and it takes exponential time and space. We show how to overcome the first three of these problems by using the DP algorithm as a proposal distribution for MCMC in DAG space. We show that this hybrid technique converges to the posterior faster than other methods, resulting in more accurate structure learning and higher predictive likelihoods on test data.},
	urldate = {2018-06-20},
	journal = {arXiv:1206.5247 [cs, stat]},
	author = {Eaton, Daniel and Murphy, Kevin},
	month = jun,
	year = {2012},
	note = {arXiv: 1206.5247},
	keywords = {Computer Science - Learning, Statistics - Machine Learning},
	annote = {Comment: Appears in Proceedings of the Twenty-Third Conference on Uncertainty in Artificial Intelligence (UAI2007)}
}

@article{tsamardinos_max-min_2006-2,
	title = {The max-min hill-climbing {Bayesian} network structure learning algorithm},
	volume = {65},
	number = {1},
	journal = {Machine learning},
	author = {Tsamardinos, Ioannis and Brown, Laura E. and Aliferis, Constantin F.},
	year = {2006},
	pages = {31--78}
}

@article{campos_efficient_2011,
	title = {Efficient structure learning of {Bayesian} networks using constraints},
	volume = {12},
	number = {Mar},
	journal = {Journal of Machine Learning Research},
	author = {Campos, Cassio P. de and Ji, Qiang},
	year = {2011},
	pages = {663--689}
}

@book{vanderbei_linear_2015,
	title = {Linear programming},
	publisher = {Springer},
	author = {Vanderbei, Robert J.},
	year = {2015}
}

@article{heckerman_learning_1995,
	title = {Learning {Bayesian} networks: {The} combination of knowledge and statistical data},
	volume = {20},
	shorttitle = {Learning {Bayesian} networks},
	number = {3},
	journal = {Machine learning},
	author = {Heckerman, David and Geiger, Dan and Chickering, David M.},
	year = {1995},
	pages = {197--243}
}

@article{jones_experiments_2005-1,
	title = {Experiments in stochastic computation for high-dimensional graphical models},
	journal = {Statistical Science},
	author = {Jones, Beatrix and Carvalho, Carlos and Dobra, Adrian and Hans, Chris and Carter, Chris and West, Mike},
	year = {2005},
	pages = {388--400}
}

@article{madigan_bayesian_1995,
	title = {Bayesian graphical models for discrete data},
	journal = {International Statistical Review/Revue Internationale de Statistique},
	author = {Madigan, David and York, Jeremy and Allard, Denis},
	year = {1995},
	pages = {215--232}
}

@misc{noauthor_yu:_nodate,
	title = {Yu: {Training} an adaptive dialogue policy for interactive... - {Google} {Scholar}},
	url = {https://scholar.google.com/scholar?oe=utf-8&um=1&ie=UTF-8&lr&q=related:gW5HTE2nqaojLM:scholar.google.com/},
	urldate = {2018-06-20}
}

@article{yu_training_2017,
	title = {Training an adaptive dialogue policy for interactive learning of visually grounded word meanings},
	journal = {arXiv preprint arXiv:1709.10426},
	author = {Yu, Yanchao and Eshghi, Arash and Lemon, Oliver},
	year = {2017}
}

@article{degris_factored_2010,
	title = {Factored markov decision processes},
	journal = {Markov Decision Processes in Artificial Intelligence},
	author = {Degris, Thomas and Sigaud, Olivier},
	year = {2010},
	pages = {99--126}
}

@article{utgoff_decision_1997,
	title = {Decision tree induction based on efficient tree restructuring},
	volume = {29},
	number = {1},
	journal = {Machine Learning},
	author = {Utgoff, Paul E. and Berkman, Neil C. and Clouse, Jeffery A.},
	year = {1997},
	pages = {5--44}
}

@inproceedings{boutilier_frame_1996,
	title = {The frame problem and {Bayesian} network action representations},
	booktitle = {Conference of the {Canadian} {Society} for {Computational} {Studies} of {Intelligence}},
	publisher = {Springer},
	author = {Boutilier, Craig and Goldszmidt, Moisés},
	year = {1996},
	pages = {69--83}
}

@book{koller_probabilistic_2009-1,
	title = {Probabilistic graphical models: principles and techniques},
	shorttitle = {Probabilistic graphical models},
	publisher = {MIT press},
	author = {Koller, Daphne and Friedman, Nir},
	year = {2009}
}

@article{russell_artificial_2002,
	title = {Artificial {Intelligence}: {A} {Modern} {Approach} ({International} {Edition})},
	shorttitle = {Artificial intelligence},
	author = {Russell, Stuart J. and Norvig, Peter},
	year = {2002}
}

@inproceedings{teyssier_ordering-based_2005,
	title = {Ordering-based search: a simple and effective algorithm for learning {Bayesian} networks},
	shorttitle = {Ordering-based search},
	booktitle = {Proceedings of the {Twenty}-{First} {Conference} on {Uncertainty} in {Artificial} {Intelligence}},
	publisher = {AUAI Press},
	author = {Teyssier, Marc and Koller, Daphne},
	year = {2005},
	pages = {584--590}
}

@inproceedings{yuan_learning_2011,
	title = {Learning optimal {Bayesian} networks using {A}* search},
	volume = {22},
	booktitle = {{IJCAI} proceedings-international joint conference on artificial intelligence},
	author = {Yuan, Changhe and Malone, Brandon and Wu, Xiaojian},
	year = {2011},
	pages = {2186}
}

@incollection{beinlich_alarm_1989,
	title = {The {ALARM} monitoring system: {A} case study with two probabilistic inference techniques for belief networks},
	shorttitle = {The {ALARM} monitoring system},
	booktitle = {{AIME} 89},
	publisher = {Springer},
	author = {Beinlich, Ingo A. and Suermondt, Henri Jacques and Chavez, R. Martin and Cooper, Gregory F.},
	year = {1989},
	pages = {247--256}
}

@misc{noauthor_bayesian_nodate,
	title = {Bayesian {Network} {Repository}},
	url = {http://www.cs.huji.ac.il/~galel/Repository/},
	urldate = {2018-07-11}
}

@inproceedings{st-aubin_apricodd:_2001,
	title = {{APRICODD}: {Approximate} policy construction using decision diagrams},
	shorttitle = {{APRICODD}},
	booktitle = {Advances in {Neural} {Information} {Processing} {Systems}},
	author = {St-Aubin, Robert and Hoey, Jesse and Boutilier, Craig},
	year = {2001},
	pages = {1089--1095}
}

@inproceedings{diuk_adaptive_2009-1,
	title = {The adaptive k-meteorologists problem and its application to structure learning and feature selection in reinforcement learning},
	booktitle = {Proceedings of the 26th {Annual} {International} {Conference} on {Machine} {Learning}},
	publisher = {ACM},
	author = {Diuk, Carlos and Li, Lihong and Leffler, Bethany R.},
	year = {2009},
	pages = {249--256}
}

@inproceedings{araya-lopez_active_2011,
	title = {Active learning of {MDP} models},
	booktitle = {European {Workshop} on {Reinforcement} {Learning}},
	publisher = {Springer},
	author = {Araya-López, Mauricio and Buffet, Olivier and Thomas, Vincent and Charpillet, François},
	year = {2011},
	pages = {42--53}
}

@inproceedings{doshi-velez_infinite_2009,
	title = {The infinite partially observable {Markov} decision process},
	booktitle = {Advances in neural information processing systems},
	author = {Doshi-Velez, Finale},
	year = {2009},
	pages = {477--485}
}

@article{dean_model_1989,
	title = {A model for reasoning about persistence and causation},
	volume = {5},
	number = {2},
	journal = {Computational intelligence},
	author = {Dean, Thomas and Kanazawa, Keiji},
	year = {1989},
	pages = {142--150}
}

@inproceedings{friedman_learning_1999,
	title = {Learning bayesian network structure from massive datasets: the sparse candidate algorithm},
	shorttitle = {Learning bayesian network structure from massive datasets},
	booktitle = {Proceedings of the {Fifteenth} conference on {Uncertainty} in artificial intelligence},
	publisher = {Morgan Kaufmann Publishers Inc.},
	author = {Friedman, Nir and Nachman, Iftach and Peér, Dana},
	year = {1999},
	pages = {206--215}
}

@article{yang_peorl:_2018,
	title = {{PEORL}: {Integrating} {Symbolic} {Planning} and {Hierarchical} {Reinforcement} {Learning} for {Robust} {Decision}-{Making}},
	shorttitle = {{PEORL}},
	journal = {arXiv preprint arXiv:1804.07779},
	author = {Yang, Fangkai and Lyu, Daoming and Liu, Bo and Gustafson, Steven},
	year = {2018}
}

@article{coenen_asking_2017,
	title = {Asking the right questions about human inquiry},
	volume = {13},
	journal = {OpenCoenen, Anna, Jonathan D Nelson, and Todd M Gureckis.“Asking the Right Questions About Human Inquiry”. PsyArXiv},
	author = {Coenen, Anna and Nelson, Jonathan D. and Gureckis, Todd M.},
	year = {2017}
}

@inproceedings{wood_non-parametric_2006,
	title = {A non-parametric {Bayesian} method for inferring hidden causes},
	booktitle = {Proceedings of the {Twenty}-{Second} {Conference} on {Uncertainty} in {Artificial} {Intelligence}},
	publisher = {AUAI Press},
	author = {Wood, Frank and Griffiths, Thomas L. and Ghahramani, Zoubin},
	year = {2006},
	pages = {536--543}
}

@article{koivisto_exact_2004,
	title = {Exact {Bayesian} structure discovery in {Bayesian} networks},
	volume = {5},
	number = {May},
	journal = {Journal of Machine Learning Research},
	author = {Koivisto, Mikko and Sood, Kismat},
	year = {2004},
	pages = {549--573}
}

@inproceedings{tian_computing_2009,
	title = {Computing posterior probabilities of structural features in {Bayesian} networks},
	booktitle = {Proceedings of the {Twenty}-{Fifth} {Conference} on {Uncertainty} in {Artificial} {Intelligence}},
	publisher = {AUAI Press},
	author = {Tian, Jin and He, Ru},
	year = {2009},
	pages = {538--547}
}